# OpenEndpoint â€” The Developer-First Object Storage Platform

## Complete Product & Architecture Vision

**Organization:** github.com/OpenEndpoint
**Primary Language:** Go 1.22+
**Dashboard:** React/Next.js (separate repo)
**Target:** Self-hosted MinIO alternative, developer-first
**Tagline:** *"Your endpoints. Your data. Your rules."*

---

## Table of Contents

1. [Product Vision & Positioning](#1-product-vision--positioning)
2. [Release Strategy (v1 â†’ v5)](#2-release-strategy)
3. [System Architecture Overview](#3-system-architecture-overview)
4. [Core Engine Deep Dive](#4-core-engine-deep-dive)
5. [Storage Backends](#5-storage-backends)
6. [Metadata Layer](#6-metadata-layer)
7. [S3 API Implementation](#7-s3-api-implementation)
8. [Authentication & Authorization](#8-authentication--authorization)
9. [Multi-Node Clustering](#9-multi-node-clustering)
10. [Multi-Region Federation](#10-multi-region-federation)
11. [Replication, Backup & Mirror](#11-replication-backup--mirror)
12. [CDN Integration & Edge](#12-cdn-integration--edge)
13. [Web Dashboard (Next.js)](#13-web-dashboard-nextjs)
14. [CLI Tool](#14-cli-tool)
15. [Observability & Monitoring](#15-observability--monitoring)
16. [Security Architecture](#16-security-architecture)
17. [Performance Engineering](#17-performance-engineering)
18. [Deployment & Operations](#18-deployment--operations)
19. [SDK & Developer Experience](#19-sdk--developer-experience)
20. [Repository Structure](#20-repository-structure)
21. [Competitive Analysis](#21-competitive-analysis)
22. [Implementation Roadmap](#22-implementation-roadmap)

---

## 1. Product Vision & Positioning

### What is OpenEndpoint?

OpenEndpoint is a **self-hosted, S3-compatible object storage platform** built from scratch in Go. It's designed for developers and teams who need complete control over their data without vendor lock-in.

### Why Not MinIO?

| Pain Point | MinIO | OpenEndpoint |
|-----------|-------|-------------|
| License | AGPLv3 (commercial license $$) | Apache 2.0 |
| Architecture | Monolithic, opinionated | Pluggable backends, modular |
| Web UI | Basic, limited | Full-featured React dashboard |
| Multi-region | Enterprise only ($$$) | Built-in, open source |
| CDN integration | Manual | Native CDN edge support |
| Developer experience | CLI-focused | CLI + Dashboard + SDKs |
| Backup/Mirror | Limited | First-class backup targets |
| Storage backends | Filesystem only | Flat file + Packed volumes + extensible |
| Clustering | Erasure coding only | Replication + Erasure coding |

### Target Users

1. **Solo developers / small teams** â€” Self-hosted S3 for side projects, media storage
2. **Startups** â€” Production object storage without AWS bills
3. **On-prem enterprises** â€” Data sovereignty, compliance requirements
4. **Platform builders** â€” White-label storage backend for SaaS products
5. **Edge/IoT** â€” Lightweight storage nodes at edge locations

### Core Principles

- **Single binary, zero external deps** â€” Download, run, done
- **S3 compatibility first** â€” Drop-in replacement for AWS S3
- **Pluggable everything** â€” Storage, metadata, auth, all swappable
- **Observable by default** â€” Metrics, logs, traces out of the box
- **Developer joy** â€” Beautiful CLI, intuitive dashboard, great docs

---

## 2. Release Strategy

### v1.0 â€” "Foundation" (Single Node)
> A solid, production-ready single-node object storage

- S3 API core (CRUD, Multipart, ListV2)
- AWS Signature V4 authentication
- Object versioning
- Lifecycle policies (expiration, noncurrent cleanup)
- Two storage backends (Flat File + Packed Volume)
- Two metadata backends (Pebble + bbolt)
- Prometheus metrics + health endpoints
- CLI tool (openep)
- Docker image + Helm chart
- Basic Web Dashboard (browse buckets, upload/download)

### v2.0 â€” "Cluster" (Multi-Node)
> Scale horizontally within a datacenter

- Node discovery & membership (gossip protocol)
- Consistent hashing for data placement
- Configurable replication (RF=1 to RF=5)
- Erasure coding (Reed-Solomon)
- Automatic rebalancing on node join/leave
- Cluster-aware Web Dashboard
- Node health monitoring & alerting
- Rolling upgrades (zero-downtime)
- Backup to external targets (S3, GCS, Azure Blob, NFS)
- Mirror mode (continuous replication to another cluster)

### v3.0 â€” "Federation" (Multi-Region)
> Span multiple datacenters and edge locations

- Multi-region federation protocol
- Geo-aware data placement
- Cross-region async replication
- Conflict resolution (vector clocks / CRDTs)
- Region-aware routing (read from nearest)
- CDN edge integration (presigned URL delegation)
- CDN cache invalidation API
- Global namespace with region affinity
- Bandwidth throttling between regions
- WAN-optimized transfer (compression, dedup)

### v4.0 â€” "Platform" (Enterprise Features)
> Enterprise-grade features for large organizations

- Multi-tenancy with resource isolation
- IAM system (users, groups, policies, roles)
- Bucket policies (S3-compatible JSON policies)
- Server-side encryption (SSE-S3, SSE-C, SSE-KMS)
- Object Lock (WORM compliance)
- S3 Event Notifications (webhook, NATS, Kafka, AMQP)
- Audit logging (immutable audit trail)
- Compliance reporting (GDPR, HIPAA data residency)
- SLA monitoring & automated failover
- White-label dashboard (custom branding)
- LDAP / OIDC authentication integration

### v5.0 â€” "Intelligence" (Smart Storage)
> AI-powered storage optimization and analytics

- S3 Select (SQL queries on CSV/JSON/Parquet)
- Intelligent tiering (hot/warm/cold/archive)
- Content-aware deduplication
- Automatic thumbnail generation for images
- Full-text search on stored documents
- Storage analytics & cost optimization
- Predictive scaling recommendations
- Data pipeline integration (Spark, Flink connectors)
- Lambda-style object transformations
- GraphQL API (alongside S3 REST)

---

## 3. System Architecture Overview

### Single Node (v1)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           Load Balancer           â”‚
                    â”‚        (nginx/caddy/traefik)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        OpenEndpoint Node          â”‚
                    â”‚                                   â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚     S3 API Gateway           â”‚  â”‚
                    â”‚  â”‚   (HTTP/HTTPS :9000)         â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚                â”‚                   â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚     Auth Middleware          â”‚  â”‚
                    â”‚  â”‚   (SigV4 + API Keys)        â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚                â”‚                   â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚      Core Engine             â”‚  â”‚
                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
                    â”‚  â”‚  â”‚ Object   â”‚Lifecycle â”‚    â”‚  â”‚
                    â”‚  â”‚  â”‚ Service  â”‚ Engine   â”‚    â”‚  â”‚
                    â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚          â”‚            â”‚            â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Metadata â”‚  â”‚   Storage     â”‚  â”‚
                    â”‚  â”‚  Store   â”‚  â”‚   Backend     â”‚  â”‚
                    â”‚  â”‚(Pebble)  â”‚  â”‚(Flat/Packed)  â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚                                   â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚  Internal API (:9001)        â”‚  â”‚
                    â”‚  â”‚  Prometheus + Health + pprof â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Multi-Node Cluster (v2)

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Load Balancer    â”‚
                         â”‚   (L7 / DNS RR)    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚              â”‚              â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
             â”‚   Node 1    â”‚â”‚   Node 2    â”‚â”‚   Node 3    â”‚
             â”‚  :9000      â”‚â”‚  :9000      â”‚â”‚  :9000      â”‚
             â”‚             â”‚â”‚             â”‚â”‚             â”‚
             â”‚ S3 API â”€â”€â”€â”€â”€â”¤â”‚ S3 API â”€â”€â”€â”€â”€â”¤â”‚ S3 API      â”‚
             â”‚ Engine      â”‚â”‚ Engine      â”‚â”‚ Engine      â”‚
             â”‚ Meta+Store  â”‚â”‚ Meta+Store  â”‚â”‚ Meta+Store  â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â”‚              â”‚              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Gossip Mesh Network      â”‚
                    â”‚   (memberlist, port :9002)    â”‚
                    â”‚                              â”‚
                    â”‚  â€¢ Node discovery            â”‚
                    â”‚  â€¢ Health checking            â”‚
                    â”‚  â€¢ Metadata propagation       â”‚
                    â”‚  â€¢ Consistent hash ring       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Data Flow (PUT with RF=3):
  Client â†’ Node1 (coordinator)
    â†’ Node1 writes locally
    â†’ Node1 forwards to Node2 (async or sync based on consistency level)
    â†’ Node1 forwards to Node3
    â†’ All 3 ACK â†’ 200 OK to client

Consistency Levels:
  â€¢ ONE    â€” 1 write ACK (fastest, risk of data loss)
  â€¢ QUORUM â€” majority ACK (balanced)
  â€¢ ALL    â€” all replicas ACK (strongest, slowest)
```

### Multi-Region Federation (v3)

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚    Global DNS / GeoDNS   â”‚
                          â”‚  (Route53 / Cloudflare)  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                      â”‚                      â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Region: EU-West    â”‚â”‚  Region: US-East    â”‚â”‚  Region: AP-South   â”‚
     â”‚   (Frankfurt)        â”‚â”‚  (Virginia)         â”‚â”‚  (Mumbai)           â”‚
     â”‚                      â”‚â”‚                      â”‚â”‚                      â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
     â”‚  â”‚  Cluster (3N)  â”‚  â”‚â”‚  â”‚  Cluster (5N)  â”‚  â”‚â”‚  â”‚  Cluster (3N)  â”‚  â”‚
     â”‚  â”‚  â”Œâ”€â”€â”â”Œâ”€â”€â”â”Œâ”€â”€â” â”‚  â”‚â”‚  â”‚ â”Œâ”€â”€â”â”Œâ”€â”€â”â”Œâ”€â”€â”  â”‚  â”‚â”‚  â”‚  â”Œâ”€â”€â”â”Œâ”€â”€â”â”Œâ”€â”€â” â”‚  â”‚
     â”‚  â”‚  â”‚N1â”‚â”‚N2â”‚â”‚N3â”‚ â”‚  â”‚â”‚  â”‚ â”‚N1â”‚â”‚N2â”‚â”‚..â”‚  â”‚  â”‚â”‚  â”‚  â”‚N1â”‚â”‚N2â”‚â”‚N3â”‚ â”‚  â”‚
     â”‚  â”‚  â””â”€â”€â”˜â””â”€â”€â”˜â””â”€â”€â”˜ â”‚  â”‚â”‚  â”‚ â””â”€â”€â”˜â””â”€â”€â”˜â””â”€â”€â”˜  â”‚  â”‚â”‚  â”‚  â””â”€â”€â”˜â””â”€â”€â”˜â””â”€â”€â”˜ â”‚  â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
     â”‚                      â”‚â”‚                      â”‚â”‚                      â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
     â”‚  â”‚ Region Gateway  â”‚  â”‚â”‚  â”‚ Region Gateway  â”‚  â”‚â”‚  â”‚ Region Gateway  â”‚  â”‚
     â”‚  â”‚ :9003           â”‚  â”‚â”‚  â”‚ :9003           â”‚  â”‚â”‚  â”‚ :9003           â”‚  â”‚
     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                       â”‚                       â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Federation Control Plane   â”‚
                         â”‚                              â”‚
                         â”‚  â€¢ Region registry           â”‚
                         â”‚  â€¢ Replication policy engine  â”‚
                         â”‚  â€¢ Conflict resolution        â”‚
                         â”‚  â€¢ Bandwidth management       â”‚
                         â”‚  â€¢ Global metadata index      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Replication Modes:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ASYNC  â€” Write to local â†’ ACK â†’ replicate later     â”‚
  â”‚          Best for: High throughput, eventual consistencyâ”‚
  â”‚                                                       â”‚
  â”‚ SEMI   â€” Write to local + 1 remote â†’ ACK             â”‚
  â”‚          Best for: Balance of speed and durability     â”‚
  â”‚                                                       â”‚
  â”‚ SYNC   â€” Write to ALL regions â†’ ACK                   â”‚
  â”‚          Best for: Critical data, strong consistency   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Full Platform with CDN (v3+)

```
                              End Users
                           â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                           â”‚            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
                    â”‚  CDN     â”‚   â”‚  CDN     â”‚
                    â”‚  Edge    â”‚   â”‚  Edge    â”‚
                    â”‚  (PoP)   â”‚   â”‚  (PoP)   â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚              â”‚
              Cache Miss â”‚    Cache Miss â”‚
                         â”‚              â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                    â”‚   CDN Origin Shield     â”‚
                    â”‚   (optional, reduces    â”‚
                    â”‚    origin load)          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   OpenEndpoint           â”‚
                    â”‚   Origin Cluster         â”‚
                    â”‚                          â”‚
                    â”‚   /cdn/v1/{bucket}/{key}  â”‚
                    â”‚   â€¢ Presigned URL gen     â”‚
                    â”‚   â€¢ Cache-Control headers â”‚
                    â”‚   â€¢ Range request support â”‚
                    â”‚   â€¢ Conditional requests  â”‚
                    â”‚     (ETag, Last-Modified) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Core Engine Deep Dive

### ObjectService â€” The Orchestrator

```go
package engine

// ObjectService is the central orchestrator.
// It coordinates between metadata, storage, auth, versioning,
// and lifecycle â€” but contains NO storage logic itself.
type ObjectService struct {
    meta       metadata.MetadataStore
    storage    storage.StorageBackend
    locker     *ShardedLocker
    lifecycle  *LifecycleEngine
    placement  cluster.PlacementStrategy  // v1: LocalPlacement
    registry   cluster.NodeRegistry       // v1: SingleNodeRegistry
    replicator *Replicator                // v2: handles cross-node replication
    metrics    *Metrics
    logger     *zap.Logger
}

// PutObject â€” The complete write path
func (s *ObjectService) PutObject(ctx context.Context, req PutObjectRequest) (PutObjectResponse, error) {
    // 1. Validate request
    if err := validateBucketName(req.Bucket); err != nil {
        return PutObjectResponse{}, err
    }
    if err := validateObjectKey(req.Key); err != nil {
        return PutObjectResponse{}, err
    }

    // 2. Check bucket exists and get versioning state
    bucket, err := s.meta.GetBucket(ctx, req.Bucket)
    if err != nil {
        return PutObjectResponse{}, ErrNoSuchBucket
    }

    // 3. Determine placement (v1: always local)
    nodes, err := s.placement.PlaceObject(req.Bucket, req.Key, bucket.ReplicationFactor)
    if err != nil {
        return PutObjectResponse{}, err
    }

    // 4. Acquire per-object lock
    unlock := s.locker.Lock(req.Bucket, req.Key)
    defer unlock()

    // 5. Generate version ID
    versionID := ""
    if bucket.VersioningEnabled {
        versionID = generateUUIDv7()
    }

    // 6. Hash the data while writing (streaming, no buffering)
    hashReader := NewHashingReader(req.Body) // computes MD5 + SHA256 on the fly

    // 7. Write to storage backend
    timer := s.metrics.StorageWriteDuration.Start()
    storageID, err := s.storage.Put(ctx, hashReader, req.ContentLength)
    timer.Stop()
    if err != nil {
        return PutObjectResponse{}, fmt.Errorf("storage write: %w", err)
    }

    // 8. Build metadata
    meta := metadata.ObjectMeta{
        Bucket:      req.Bucket,
        Key:         req.Key,
        VersionID:   versionID,
        StorageID:   storageID,
        Size:        hashReader.BytesRead(),
        ETag:        hashReader.MD5Hex(),
        ContentType: req.ContentType,
        UserMeta:    req.UserMeta,
        IsLatest:    true,
        CreatedAt:   time.Now().UTC(),
    }

    // 9. Apply lifecycle rules (compute expiration)
    if bucket.LifecycleRules != nil {
        meta.ExpiresAt = s.lifecycle.ComputeExpiration(meta, bucket.LifecycleRules)
    }

    // 10. Write metadata (returns old StorageID if overwriting)
    oldStorageID, err := s.meta.PutObjectMeta(ctx, meta)
    if err != nil {
        // Rollback: delete the data we just wrote
        s.storage.Delete(ctx, storageID)
        return PutObjectResponse{}, fmt.Errorf("metadata write: %w", err)
    }

    // 11. Async cleanup of old version data
    if oldStorageID != nil {
        go s.storage.Delete(context.Background(), *oldStorageID)
    }

    // 12. Async replication to other nodes (v2+)
    if len(nodes) > 1 {
        go s.replicator.ReplicateObject(context.Background(), meta, nodes[1:])
    }

    // 13. Metrics
    s.metrics.ObjectsPut.Inc()
    s.metrics.BytesWritten.Add(float64(meta.Size))

    return PutObjectResponse{
        ETag:      meta.ETag,
        VersionID: meta.VersionID,
    }, nil
}
```

### Streaming Architecture â€” Zero-Copy Where Possible

```
PutObject Request Flow (zero unnecessary copies):

  HTTP Body (io.Reader)
       â”‚
       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ HashingReader   â”‚ â† Wraps original reader
  â”‚ (MD5 + SHA256)  â”‚    Computes hashes on-the-fly
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    No buffering in memory
          â”‚
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ StorageBackend  â”‚
  â”‚                â”‚
  â”‚ Flat: io.Copy  â”‚ â† Direct to file descriptor
  â”‚   to file      â”‚    Uses sendfile(2) when possible
  â”‚                â”‚
  â”‚ Packed: io.Copyâ”‚ â† Direct append to volume file
  â”‚   to volume    â”‚    Single sequential write
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

GetObject Response Flow:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ StorageBackend  â”‚
  â”‚                â”‚
  â”‚ Flat: os.Open  â”‚ â† File descriptor
  â”‚                â”‚
  â”‚ Packed: pread  â”‚ â† Positional read, no seek contention
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ http.ServeContent â”‚ â† Handles Range requests automatically
  â”‚ or io.Copy     â”‚    Uses sendfile(2) kernel â†’ socket
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    Zero user-space copies
          â”‚
          â–¼
  HTTP Response Body
```

---

## 5. Storage Backends

### 5.1 Backend Interface

```go
package storage

type Backend interface {
    // Data operations
    Put(ctx context.Context, reader io.Reader, size int64) (ObjectID, error)
    Get(ctx context.Context, id ObjectID) (io.ReadCloser, error)
    GetRange(ctx context.Context, id ObjectID, offset, length int64) (io.ReadCloser, error)
    Delete(ctx context.Context, id ObjectID) error
    Stat(ctx context.Context, id ObjectID) (ObjectStat, error)

    // Maintenance
    SpaceInfo(ctx context.Context) (SpaceInfo, error)
    Compact(ctx context.Context) error          // packed: volume compaction
    Verify(ctx context.Context, id ObjectID) error  // integrity check

    // Lifecycle
    Init(ctx context.Context) error
    Close() error

    // Backend info
    Name() string                               // "flatfile" | "packed"
    Capabilities() BackendCapabilities
}

type BackendCapabilities struct {
    SupportsRangeRead    bool
    SupportsAtomicWrite  bool
    SupportsCompaction   bool
    MaxObjectSize        int64
    RecommendedObjSize   Range  // optimal object size range
}
```

### 5.2 Flat File Backend

```
Disk Layout:
/var/lib/openendpoint/data/
â”œâ”€â”€ flatfile/
â”‚   â”œâ”€â”€ ab/                          # 2-char hex prefix (256 dirs)
â”‚   â”‚   â”œâ”€â”€ ab3f7e...uuid.dat       # object data
â”‚   â”‚   â”œâ”€â”€ ab3f7e...uuid.dat.meta  # optional: inline metadata cache
â”‚   â”‚   â””â”€â”€ ab8c2a...uuid.dat
â”‚   â”œâ”€â”€ cd/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ tmp/                         # atomic write staging
â”‚       â””â”€â”€ .write-{uuid}.tmp
```

**Write Strategy:**
```
1. Create temp file in tmp/ directory
2. io.Copy from reader â†’ temp file
3. fsync temp file
4. Rename temp â†’ final path (atomic on POSIX)
5. fsync parent directory (ensures directory entry is durable)
```

**Optimization: O_DIRECT for Large Objects**
```go
func (f *FlatFile) Put(ctx context.Context, r io.Reader, size int64) (ObjectID, error) {
    id := ObjectID(uuid.Must(uuid.NewV7()).String())
    finalPath := f.objectPath(id)
    tmpPath := f.tempPath(id)

    flags := os.O_CREATE | os.O_WRONLY | os.O_EXCL
    if size > f.directIOThreshold { // default: 4MB
        flags |= syscall.O_DIRECT
    }

    file, err := os.OpenFile(tmpPath, flags, 0o640)
    if err != nil {
        return "", fmt.Errorf("create temp: %w", err)
    }

    var writer io.Writer = file
    if flags&syscall.O_DIRECT != 0 {
        // O_DIRECT requires aligned writes
        writer = NewAlignedWriter(file, 4096) // 4KB alignment
    }

    hash := md5.New()
    written, err := io.Copy(io.MultiWriter(writer, hash), r)
    // ... fsync, rename, return
}
```

**Recommended for:** Objects > 1MB, simple deployments, debugging ease.

### 5.3 Packed Volume Backend (Haystack-inspired)

```
Disk Layout:
/var/lib/openendpoint/data/
â”œâ”€â”€ packed/
â”‚   â”œâ”€â”€ volumes/
â”‚   â”‚   â”œâ”€â”€ vol-000001.dat          # 1GB volume file
â”‚   â”‚   â”œâ”€â”€ vol-000001.idx          # persisted index snapshot
â”‚   â”‚   â”œâ”€â”€ vol-000002.dat          # sealed volume
â”‚   â”‚   â”œâ”€â”€ vol-000002.idx
â”‚   â”‚   â””â”€â”€ vol-000003.dat          # active (writable) volume
â”‚   â”œâ”€â”€ wal/
â”‚   â”‚   â”œâ”€â”€ 000001.wal             # write-ahead log segments
â”‚   â”‚   â””â”€â”€ 000002.wal
â”‚   â””â”€â”€ compaction/
â”‚       â””â”€â”€ .compact-{uuid}.tmp     # compaction staging
```

**Volume File Binary Format:**

```
Volume File (.dat):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Volume Header (128 bytes)                                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚  Magic   â”‚ Version â”‚ VolumeID â”‚ Created  â”‚  Flags        â”‚â”‚
â”‚ â”‚  (8B)    â”‚  (4B)   â”‚  (4B)    â”‚  (8B)    â”‚  (4B)         â”‚â”‚
â”‚ â”‚ OPENEPV1 â”‚  0x01   â”‚  uint32  â”‚ unix_ns  â”‚ sealed/active â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚ MaxSize  â”‚ NeedleCount â”‚ DataSize  â”‚ Reserved (76B)       â”‚â”‚
â”‚ â”‚  (8B)    â”‚   (8B)      â”‚  (8B)     â”‚                      â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Needle 0                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Magic  â”‚ Flags â”‚ ID   â”‚ Size  â”‚  CRC32  â”‚  Padding       â”‚â”‚
â”‚ â”‚ (4B)   â”‚ (1B)  â”‚(16B) â”‚ (8B)  â”‚  (4B)   â”‚  (0-7B)        â”‚â”‚
â”‚ â”‚0xNEEDLEâ”‚       â”‚ UUID â”‚uint64 â”‚ of data â”‚  to 8B align   â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚                    Data Payload                           â”‚â”‚
â”‚ â”‚               (variable length, 8-byte aligned)           â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Needle 1 ...                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Needle N ...                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Needle Flags:
  0x00 = Active
  0x01 = Deleted (tombstone)
  0x02 = Compressed (zstd)
  0x04 = Encrypted (AES-256-GCM, v4)

Total Needle overhead: 33 bytes + padding (max 40 bytes)
```

**Index File Format:**

```
Index (.idx) â€” Memory-mapped for fast lookups:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Index Header (64 bytes)                       â”‚
â”‚ â”‚ Magic â”‚ Version â”‚ VolumeID â”‚ EntryCount â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Entry 0:  [ObjectID(16B)] [Offset(8B)] [Size(8B)] [Flags(1B)] â”‚
â”‚ Entry 1:  [ObjectID(16B)] [Offset(8B)] [Size(8B)] [Flags(1B)] â”‚
â”‚ ...                                          â”‚
â”‚ Entry N:  ...                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

In-memory: loaded into map[ObjectID]NeedleLocation on startup
Persistence: snapshot every 60s + WAL for crash recovery
```

**Compaction Process:**

```
Phase 1: Analysis
  - Scan volume, count active vs deleted needles
  - If deleted_ratio < threshold (30%), skip

Phase 2: Copy
  - Create new volume file
  - Copy all active needles (sequential read â†’ sequential write)
  - Build new index

Phase 3: Swap (atomic)
  - Rename new volume â†’ old volume path
  - Swap in-memory index atomically
  - Delete old volume file

Phase 4: Verify
  - Read-verify random sample of needles in new volume
  - Compare CRC32 checksums

Compaction is:
  - Non-blocking (reads continue from old volume until swap)
  - Rate-limited (configurable IO bandwidth cap)
  - Resumable (checkpoint progress to WAL)
```

**Recommended for:** Small objects (< 1MB), high IOPS workloads, massive object counts.

### 5.4 Future: Tiered Backend (v5)

```go
// Tiered backend routes objects to different backends based on rules
type TieredBackend struct {
    hot    Backend  // Packed volumes on NVMe SSD
    warm   Backend  // Flat files on HDD
    cold   Backend  // Compressed flat files on object storage (S3/GCS)
    rules  []TieringRule
}

type TieringRule struct {
    Condition  TieringCondition  // age, access pattern, size
    TargetTier string            // "hot", "warm", "cold"
}
```

---

## 6. Metadata Layer

### 6.1 Key Schema Design

All metadata is stored in a key-value store with carefully designed key schemas for efficient queries.

```
Key Prefixes and Schemas:

BUCKET METADATA:
  b:{bucket_name}                         â†’ BucketMeta (JSON)

OBJECT METADATA (Latest Pointer):
  o:{bucket}:{key}                        â†’ LatestPointer {versionID, isDeleteMarker}

OBJECT VERSIONS:
  v:{bucket}:{key}:{versionID}            â†’ ObjectMeta (JSON)
  â”‚                    â”‚
  â”‚                    â””â”€â”€ UUID v7 (time-sortable, lexicographic order)
  â”‚                        Newest version = last in range scan
  â””â”€â”€ Enables efficient prefix scan for "list all versions of key"

DELETE MARKERS:
  d:{bucket}:{key}:{versionID}            â†’ DeleteMarkerMeta

OBJECT LISTING INDEX (for ListObjectsV2):
  l:{bucket}:{key}                        â†’ ObjectListEntry {size, etag, lastModified}
  â”‚
  â””â”€â”€ Separate index for listing = fast prefix scan
      without loading full ObjectMeta

MULTIPART UPLOADS:
  m:{uploadID}                            â†’ MultipartMeta {bucket, key, created}
  p:{uploadID}:{partNumber:05d}           â†’ PartMeta {storageID, size, etag}

LIFECYCLE INDEX:
  e:{expiresAt:unix}:{bucket}:{key}       â†’ ExpirationEntry
  â”‚
  â””â”€â”€ Time-prefixed = range scan for "expired before now" is trivial

STORAGE BACKEND MAPPING (for backend migration):
  s:{storageID}                           â†’ StorageLocation {backend, volumeID, offset}

CLUSTER METADATA (v2):
  c:nodes:{nodeID}                        â†’ NodeInfo
  c:ring                                  â†’ HashRingSnapshot
  c:rebalance:{taskID}                    â†’ RebalanceTask

REPLICATION LOG (v2):
  r:{timestamp}:{bucket}:{key}            â†’ ReplicationEntry
```

### 6.2 Pebble Implementation Notes

```go
package pebblestore

import (
    "github.com/cockroachdb/pebble"
)

type PebbleStore struct {
    db     *pebble.DB
    cache  *pebble.Cache
}

func NewPebbleStore(dir string, cacheSize int64) (*PebbleStore, error) {
    cache := pebble.NewCache(cacheSize) // default: 256MB
    defer cache.Unref()

    opts := &pebble.Options{
        Cache:                       cache,
        MaxConcurrentCompactions:    func() int { return 4 },
        L0CompactionThreshold:       4,
        L0StopWritesThreshold:       12,
        LBaseMaxBytes:               64 << 20, // 64MB
        MaxOpenFiles:                1000,
        MemTableSize:                64 << 20, // 64MB
        MemTableStopWritesThreshold: 4,

        // Bloom filters for point lookups
        Levels: []pebble.LevelOptions{
            {TargetFileSize: 16 << 20, FilterPolicy: bloom.FilterPolicy(10)},
            {TargetFileSize: 32 << 20, FilterPolicy: bloom.FilterPolicy(10)},
            {TargetFileSize: 64 << 20},
            {TargetFileSize: 128 << 20},
            {TargetFileSize: 256 << 20},
            {TargetFileSize: 512 << 20},
            {TargetFileSize: 512 << 20},
        },
    }

    db, err := pebble.Open(dir, opts)
    if err != nil {
        return nil, err
    }

    return &PebbleStore{db: db, cache: cache}, nil
}

// ListObjects uses prefix iteration â€” very efficient in LSM trees
func (p *PebbleStore) ListObjects(ctx context.Context, bucket string, opts ListOptions) (ListResult, error) {
    prefix := []byte(fmt.Sprintf("l:%s:", bucket))
    if opts.Prefix != "" {
        prefix = append(prefix, []byte(opts.Prefix)...)
    }

    iter, _ := p.db.NewIter(&pebble.IterOptions{
        LowerBound: prefix,
        UpperBound: incrementBytes(prefix), // prefix + 1 for range end
    })
    defer iter.Close()

    var result ListResult
    count := 0

    // Seek to StartAfter position if paginating
    if opts.StartAfter != "" {
        startKey := []byte(fmt.Sprintf("l:%s:%s", bucket, opts.StartAfter))
        iter.SeekGE(startKey)
        if iter.Valid() {
            iter.Next() // skip the StartAfter key itself
        }
    } else {
        iter.First()
    }

    for ; iter.Valid() && count < opts.MaxKeys; iter.Next() {
        key := string(iter.Key())
        objectKey := extractObjectKey(key, bucket)

        // Handle delimiter (directory simulation)
        if opts.Delimiter != "" {
            afterPrefix := strings.TrimPrefix(objectKey, opts.Prefix)
            if idx := strings.Index(afterPrefix, opts.Delimiter); idx >= 0 {
                commonPrefix := opts.Prefix + afterPrefix[:idx+len(opts.Delimiter)]
                result.CommonPrefixes = appendUnique(result.CommonPrefixes, commonPrefix)
                // Skip all keys with this common prefix
                skipTo := []byte(fmt.Sprintf("l:%s:%s", bucket, commonPrefix))
                iter.SeekGE(incrementBytes(skipTo))
                continue
            }
        }

        var entry ObjectListEntry
        json.Unmarshal(iter.Value(), &entry)
        result.Objects = append(result.Objects, entry.ToObjectMeta(bucket, objectKey))
        count++
    }

    if iter.Valid() {
        result.IsTruncated = true
        result.NextMarker = result.Objects[len(result.Objects)-1].Key
    }

    return result, nil
}
```

### 6.3 Metadata Consistency Guarantees

| Operation | Guarantee | Implementation |
|-----------|-----------|----------------|
| PutObjectMeta | Atomic per-key | Pebble batch write (all-or-nothing) |
| GetObjectMeta | Read-your-writes | Pebble point lookup (always sees latest) |
| ListObjects | Snapshot consistency | Pebble snapshot iterator |
| DeleteObjectMeta | Atomic | Pebble batch delete + insert (delete marker) |
| BucketVersioning toggle | Atomic | Single key update |

---

## 7. S3 API Implementation

### 7.1 API Coverage Matrix

```
v1 API Coverage:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 Bucket Operations                          Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 CreateBucket          PUT /{bucket}         âœ… v1
 DeleteBucket          DELETE /{bucket}      âœ… v1
 HeadBucket            HEAD /{bucket}        âœ… v1
 ListBuckets           GET /                 âœ… v1
 GetBucketLocation     GET /?location        âœ… v1
 GetBucketVersioning   GET /?versioning      âœ… v1
 PutBucketVersioning   PUT /?versioning      âœ… v1
 PutBucketLifecycle    PUT /?lifecycle       âœ… v1
 GetBucketLifecycle    GET /?lifecycle       âœ… v1
 DeleteBucketLifecycle DELETE /?lifecycle    âœ… v1

 Object Operations
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 PutObject             PUT /{bucket}/{key}   âœ… v1
 GetObject             GET /{bucket}/{key}   âœ… v1
 HeadObject            HEAD /{bucket}/{key}  âœ… v1
 DeleteObject          DELETE /{bucket}/{key} âœ… v1
 DeleteObjects         POST /?delete         âœ… v1 (batch)
 CopyObject            PUT + x-amz-copy-src  âœ… v1
 ListObjectsV2         GET /?list-type=2     âœ… v1
 ListObjectVersions    GET /?versions        âœ… v1

 Multipart Upload
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 InitiateMultipart     POST /?uploads        âœ… v1
 UploadPart            PUT ?partNumber&upId   âœ… v1
 CompleteMultipart     POST ?uploadId         âœ… v1
 AbortMultipart        DELETE ?uploadId       âœ… v1
 ListParts             GET ?uploadId          âœ… v1
 ListMultipartUploads  GET /?uploads          âœ… v1

 Presigned URLs
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Presigned GET         query string auth     âœ… v1
 Presigned PUT         query string auth     âœ… v1

v2+ API Coverage:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 PutBucketPolicy       PUT /?policy          ğŸ”® v4
 GetBucketPolicy       GET /?policy          ğŸ”® v4
 PutBucketEncryption   PUT /?encryption      ğŸ”® v4
 PutObjectLockConfig   PUT /?object-lock     ğŸ”® v4
 PutBucketNotification PUT /?notification    ğŸ”® v4
 SelectObjectContent   POST /?select         ğŸ”® v5
 PutBucketReplication  PUT /?replication     ğŸ”® v3
```

### 7.2 Request Routing Logic

```go
// S3 has complex routing â€” same path, different operations based on query params
func (h *Handler) routeRequest(w http.ResponseWriter, r *http.Request) {
    bucket, key := parsePath(r)
    query := r.URL.Query()

    switch {
    // Bucket-level operations (no key)
    case key == "":
        switch r.Method {
        case "GET":
            if bucket == "" {
                h.ListBuckets(w, r)                    // GET /
            } else if query.Has("uploads") {
                h.ListMultipartUploads(w, r)           // GET /bucket?uploads
            } else if query.Has("versioning") {
                h.GetBucketVersioning(w, r)            // GET /bucket?versioning
            } else if query.Has("lifecycle") {
                h.GetBucketLifecycle(w, r)             // GET /bucket?lifecycle
            } else if query.Has("versions") {
                h.ListObjectVersions(w, r)             // GET /bucket?versions
            } else if query.Has("location") {
                h.GetBucketLocation(w, r)              // GET /bucket?location
            } else {
                h.ListObjectsV2(w, r)                  // GET /bucket (+ list-type=2)
            }
        case "PUT":
            if query.Has("versioning") {
                h.PutBucketVersioning(w, r)
            } else if query.Has("lifecycle") {
                h.PutBucketLifecycle(w, r)
            } else {
                h.CreateBucket(w, r)
            }
        case "DELETE":
            h.DeleteBucket(w, r)
        case "HEAD":
            h.HeadBucket(w, r)
        }

    // Object-level operations (bucket + key)
    default:
        switch r.Method {
        case "GET":
            if query.Has("uploadId") {
                h.ListParts(w, r)
            } else {
                h.GetObject(w, r)
            }
        case "PUT":
            if query.Has("partNumber") && query.Has("uploadId") {
                h.UploadPart(w, r)
            } else if r.Header.Get("x-amz-copy-source") != "" {
                h.CopyObject(w, r)
            } else {
                h.PutObject(w, r)
            }
        case "DELETE":
            if query.Has("uploadId") {
                h.AbortMultipartUpload(w, r)
            } else {
                h.DeleteObject(w, r)
            }
        case "POST":
            if query.Has("uploads") {
                h.InitiateMultipartUpload(w, r)
            } else if query.Has("uploadId") {
                h.CompleteMultipartUpload(w, r)
            } else if query.Has("delete") {
                h.DeleteObjects(w, r)
            }
        case "HEAD":
            h.HeadObject(w, r)
        }
    }
}
```

### 7.3 Virtual-Hosted Style Support

```go
// S3 supports two URL styles:
//   Path-style:    https://s3.example.com/bucket/key
//   Virtual-host:  https://bucket.s3.example.com/key

func (h *Handler) extractBucketKey(r *http.Request) (string, string) {
    host := r.Host

    // Check for virtual-hosted style
    if h.config.VirtualHostDomain != "" {
        suffix := "." + h.config.VirtualHostDomain
        if strings.HasSuffix(host, suffix) {
            bucket := strings.TrimSuffix(host, suffix)
            key := strings.TrimPrefix(r.URL.Path, "/")
            return bucket, key
        }
    }

    // Fall back to path-style
    parts := strings.SplitN(strings.TrimPrefix(r.URL.Path, "/"), "/", 2)
    bucket := parts[0]
    key := ""
    if len(parts) > 1 {
        key = parts[1]
    }
    return bucket, key
}
```

---

## 8. Authentication & Authorization

### 8.1 AWS Signature V4 (v1)

```
Authorization: AWS4-HMAC-SHA256
  Credential=AKID/20240101/us-east-1/s3/aws4_request,
  SignedHeaders=content-type;host;x-amz-content-sha256;x-amz-date,
  Signature=fe5f80f77d5fa3beca038a248ff027d0445342fe2855ddc963176630326f1024

Verification Steps:
  1. Parse Authorization header
  2. Extract Access Key â†’ look up Secret Key
  3. Build Canonical Request:
     - HTTP method
     - URI (path-encoded)
     - Query string (sorted)
     - Canonical headers (lowercase, sorted)
     - Signed headers list
     - Payload hash (x-amz-content-sha256 header)
  4. Build String to Sign:
     - Algorithm: AWS4-HMAC-SHA256
     - Timestamp: x-amz-date header
     - Credential scope: date/region/s3/aws4_request
     - SHA256(Canonical Request)
  5. Derive signing key:
     - HMAC(HMAC(HMAC(HMAC("AWS4"+secret, date), region), "s3"), "aws4_request")
  6. Calculate HMAC-SHA256(signing_key, string_to_sign)
  7. Compare with provided signature (constant-time)
  8. Check timestamp (Â±15 minutes)

Special Cases:
  - Chunked uploads: x-amz-content-sha256 = "STREAMING-AWS4-HMAC-SHA256-PAYLOAD"
  - Unsigned payload: x-amz-content-sha256 = "UNSIGNED-PAYLOAD"
  - Presigned URLs: signature in query params, not header
```

### 8.2 Presigned URL Implementation

```go
// Presigned URLs allow temporary access without credentials
func (a *AuthService) GeneratePresignedURL(bucket, key string, expiry time.Duration, method string) (string, error) {
    now := time.Now().UTC()
    credential := fmt.Sprintf("%s/%s/%s/s3/aws4_request",
        a.accessKey,
        now.Format("20060102"),
        a.region,
    )

    params := url.Values{
        "X-Amz-Algorithm":     {"AWS4-HMAC-SHA256"},
        "X-Amz-Credential":    {credential},
        "X-Amz-Date":          {now.Format("20060102T150405Z")},
        "X-Amz-Expires":       {strconv.Itoa(int(expiry.Seconds()))},
        "X-Amz-SignedHeaders":  {"host"},
    }

    // Build canonical request with query params
    canonicalRequest := buildCanonicalRequestForPresign(method, bucket, key, params)
    stringToSign := buildStringToSign(now, canonicalRequest)
    signature := sign(a.signingKey, stringToSign)

    params.Set("X-Amz-Signature", signature)

    return fmt.Sprintf("%s/%s/%s?%s",
        a.endpoint, bucket, key, params.Encode()), nil
}
```

### 8.3 IAM System (v4)

```
Role-Based Access Control:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Tenant                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Users   â”‚  â”‚ Groups  â”‚  â”‚  Policies   â”‚ â”‚
â”‚  â”‚          â”‚  â”‚         â”‚  â”‚             â”‚ â”‚
â”‚  â”‚ alice â”€â”€â”€â”¼â”€â”€â–º admins â”€â”¼â”€â”€â–º FullAccess  â”‚ â”‚
â”‚  â”‚ bob   â”€â”€â”€â”¼â”€â”€â–º devs  â”€â”€â”¼â”€â”€â–º ReadOnly    â”‚ â”‚
â”‚  â”‚ carol â”€â”€â”€â”¼â”€â”€â–º ops   â”€â”€â”¼â”€â”€â–º WriteMedia  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Policy Format (S3-compatible):
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": ["s3:GetObject", "s3:ListBucket"],
    "Resource": [
      "arn:openep:s3:::my-bucket",
      "arn:openep:s3:::my-bucket/*"
    ],
    "Condition": {
      "IpAddress": {"aws:SourceIp": "192.168.1.0/24"},
      "StringLike": {"s3:prefix": "public/*"}
    }
  }]
}
```

---

## 9. Multi-Node Clustering (v2)

### 9.1 Node Discovery â€” Gossip Protocol

```go
import "github.com/hashicorp/memberlist"

type ClusterManager struct {
    list       *memberlist.Memberlist
    events     chan MemberEvent
    hashRing   *ConsistentHashRing
    localNode  NodeInfo
}

func NewClusterManager(config ClusterConfig) (*ClusterManager, error) {
    mlConfig := memberlist.DefaultLANConfig()
    mlConfig.Name = config.NodeName
    mlConfig.BindPort = config.GossipPort        // default: 9002
    mlConfig.AdvertiseAddr = config.AdvertiseAddr

    cm := &ClusterManager{
        events:   make(chan MemberEvent, 100),
        hashRing: NewConsistentHashRing(config.VirtualNodes), // default: 256 vnodes
    }

    mlConfig.Events = &memberlistEventDelegate{ch: cm.events}
    mlConfig.Delegate = &stateDelegate{node: cm.localNode}

    list, err := memberlist.Create(mlConfig)
    if err != nil {
        return nil, err
    }

    // Join existing cluster
    if len(config.JoinAddrs) > 0 {
        _, err = list.Join(config.JoinAddrs)
    }

    cm.list = list
    go cm.handleEvents() // process join/leave events
    return cm, nil
}

func (cm *ClusterManager) handleEvents() {
    for event := range cm.events {
        switch event.Type {
        case NodeJoin:
            cm.hashRing.AddNode(event.Node)
            cm.triggerRebalance(event.Node)
        case NodeLeave:
            cm.hashRing.RemoveNode(event.Node)
            cm.triggerReRepair(event.Node)
        case NodeUpdate:
            cm.hashRing.UpdateNode(event.Node)
        }
    }
}
```

### 9.2 Consistent Hashing Ring

```
Hash Ring with Virtual Nodes:

             Node A (vnodes: a1, a2, a3, ...)
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚                                       â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                 â”‚
    â”‚    â”‚    a1      â”‚                                 â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
    â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
    â”‚          â”‚   c2     â”‚  Node C                    â”‚
    â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
    â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
    â”‚                    â”‚   b1     â”‚  Node B          â”‚
    â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
    â”‚   â”‚   a2     â”‚  Node A                          â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
    â”‚              â”‚   b2     â”‚  Node B               â”‚
    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
    â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚                       â”‚   c1     â”‚  Node C     â”‚
    â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
    â”‚   â”‚   a3     â”‚  Node A                          â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Object Placement (RF=3):
  hash("my-bucket/photo.jpg") = 0x7A3F...
  â†’ Walk ring clockwise â†’ find 3 distinct physical nodes
  â†’ Primary: Node B (b1)
  â†’ Replica1: Node C (c1)
  â†’ Replica2: Node A (a3)
```

```go
type ConsistentHashRing struct {
    mu           sync.RWMutex
    ring         []ringEntry        // sorted by hash
    vnodeCount   int                // virtual nodes per physical node
    nodes        map[NodeID]NodeInfo
    replicaCount int                // replication factor
}

type ringEntry struct {
    hash   uint64
    nodeID NodeID
}

func (r *ConsistentHashRing) GetNodes(key string, count int) []NodeID {
    r.mu.RLock()
    defer r.mu.RUnlock()

    hash := xxhash.Sum64String(key)
    idx := sort.Search(len(r.ring), func(i int) bool {
        return r.ring[i].hash >= hash
    })

    seen := make(map[NodeID]bool)
    var result []NodeID

    for len(result) < count && len(result) < len(r.nodes) {
        entry := r.ring[idx%len(r.ring)]
        if !seen[entry.nodeID] {
            seen[entry.nodeID] = true
            result = append(result, entry.nodeID)
        }
        idx++
    }

    return result
}
```

### 9.3 Write Path (Clustered)

```
Client PUT /bucket/key
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Any Node â”‚ â† receives request (coordinator)
    â”‚ (Gateway) â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
          â”‚
          â–¼
    Hash("bucket/key") â†’ Ring Lookup â†’ [NodeA, NodeB, NodeC]
          â”‚
          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                                          â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚  Primary    â”‚  â”‚  Replica 1    â”‚  â”‚   Replica 2      â”‚
    â”‚  (NodeA)    â”‚  â”‚  (NodeB)      â”‚  â”‚   (NodeC)        â”‚
    â”‚             â”‚  â”‚               â”‚  â”‚                  â”‚
    â”‚ Write data  â”‚  â”‚ Write data    â”‚  â”‚  Write data      â”‚
    â”‚ Write meta  â”‚  â”‚ Write meta    â”‚  â”‚  Write meta      â”‚
    â”‚ â”€â”€ACKâ”€â”€â–º    â”‚  â”‚ â”€â”€ACKâ”€â”€â–º      â”‚  â”‚  â”€â”€ACKâ”€â”€â–º        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    Consistency Level:
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                    â”‚   QUORUM    â”‚ â† wait for 2 of 3 ACKs
                    â”‚  (default)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    200 OK to Client
```

### 9.4 Read Repair

```
When a read detects inconsistency:

Client GET /bucket/key
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Coordinatorâ”‚
    â”‚   Node    â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
          â”‚
    â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     â”‚                    â”‚
    â–¼     â–¼                    â–¼
  NodeA  NodeB               NodeC
  v=3    v=3                 v=2 â† stale!
    â”‚     â”‚                    â”‚
    â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
    Coordinator detects version mismatch
          â”‚
          â–¼
    Background: push v=3 to NodeC (read repair)
    Foreground: return v=3 to client immediately
```

### 9.5 Anti-Entropy (Merkle Trees)

```
Periodic consistency check between replicas:

Node A                              Node B
  â”‚                                    â”‚
  â”œâ”€â”€ Build Merkle tree for bucket â”€â”€â”€â”€â”¤
  â”‚                                    â”‚
  â”‚   Root: abc123                     â”‚   Root: abc123 âœ“ (match)
  â”‚   â”œâ”€â”€ Left: def456                 â”‚   â”œâ”€â”€ Left: def456 âœ“
  â”‚   â””â”€â”€ Right: 789abc               â”‚   â””â”€â”€ Right: DIFFER âœ—
  â”‚       â”œâ”€â”€ RL: aaa111              â”‚       â”œâ”€â”€ RL: aaa111 âœ“
  â”‚       â””â”€â”€ RR: bbb222              â”‚       â””â”€â”€ RR: ccc333 âœ—
  â”‚                                    â”‚
  â”‚   Only sync the objects in RR subtree
  â”‚   (logarithmic comparison instead of full scan)
  â”‚                                    â”‚
  â”œâ”€â”€ Transfer missing/updated objectsâ”€â–ºâ”‚
  â”‚                                    â”‚
```

### 9.6 Rebalancing on Node Join

```
Before: 3 nodes, RF=2
  Data distribution: ~33% per node

New Node D joins:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  1. Update hash ring (add D's vnodes)       â”‚
  â”‚  2. Calculate ownership changes              â”‚
  â”‚     - Some ranges move from A,B,C â†’ D       â”‚
  â”‚  3. Start background transfer                â”‚
  â”‚     - Rate-limited (configurable bandwidth)  â”‚
  â”‚     - Prioritize: newest data first          â”‚
  â”‚  4. During transfer:                         â”‚
  â”‚     - Reads: serve from old owner (redirect) â”‚
  â”‚     - Writes: go to new owner immediately    â”‚
  â”‚  5. Transfer complete:                       â”‚
  â”‚     - Old copies marked for deletion         â”‚
  â”‚     - Compaction reclaims space              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After: 4 nodes, RF=2
  Data distribution: ~25% per node
  Zero downtime during entire process
```

---

## 10. Multi-Region Federation (v3)

### 10.1 Federation Architecture

```
Each region runs an independent cluster.
Federation = metadata synchronization + async data replication.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Federation Control Plane                   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Region Registry   â”‚  â”‚ Replication Policy Engine        â”‚ â”‚
â”‚  â”‚                   â”‚  â”‚                                  â”‚ â”‚
â”‚  â”‚ EU-West: active   â”‚  â”‚ Rule: bucket "media-*"           â”‚ â”‚
â”‚  â”‚ US-East: active   â”‚  â”‚   â†’ replicate to ALL regions     â”‚ â”‚
â”‚  â”‚ AP-South: active  â”‚  â”‚   â†’ mode: ASYNC                 â”‚ â”‚
â”‚  â”‚ EU-North: standby â”‚  â”‚   â†’ max_lag: 1h                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                                  â”‚ â”‚
â”‚                         â”‚ Rule: bucket "logs-*"            â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â†’ replicate to US-East only    â”‚ â”‚
â”‚  â”‚ Conflict Resolver â”‚  â”‚   â†’ mode: SEMI                  â”‚ â”‚
â”‚  â”‚                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”‚ Strategy:         â”‚                                       â”‚
â”‚  â”‚  Last-Write-Wins  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  (vector clock)   â”‚  â”‚ Bandwidth Manager                â”‚ â”‚
â”‚  â”‚                   â”‚  â”‚                                  â”‚ â”‚
â”‚  â”‚ Custom resolvers  â”‚  â”‚ EUâ†”US: 500 Mbps limit           â”‚ â”‚
â”‚  â”‚ per bucket        â”‚  â”‚ EUâ†”AP: 200 Mbps limit           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ USâ†”AP: 300 Mbps limit           â”‚ â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.2 Replication Protocol

```
Cross-Region Replication Flow:

Source Region (EU-West)           Target Region (US-East)
  â”‚                                        â”‚
  â”‚  PutObject("photo.jpg")                â”‚
  â”‚  â†’ Write locally (sync)                â”‚
  â”‚  â†’ Append to replication log           â”‚
  â”‚                                        â”‚
  â”‚  Replication Agent picks up entry      â”‚
  â”‚  â”œâ”€â”€ Read object data                  â”‚
  â”‚  â”œâ”€â”€ Compress with zstd               â”‚
  â”‚  â”œâ”€â”€ Encrypt for transit (TLS)         â”‚
  â”‚  â””â”€â”€ Stream to target region â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚                                        â”‚ Receive + decompress
  â”‚                                        â”‚ Write to local storage
  â”‚                                        â”‚ Write metadata
  â”‚                          â—„â”€â”€ ACK â”€â”€â”€â”€â”€â”€â”‚
  â”‚  Mark replication entry as complete    â”‚
  â”‚                                        â”‚
  â”‚  Replication lag metric updated        â”‚
  â”‚                                        â”‚

Replication Log Format:
  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚SeqNumâ”‚Timestampâ”‚ Bucket  â”‚  Key  â”‚Operation â”‚ Status  â”‚
  â”‚      â”‚        â”‚         â”‚       â”‚PUT/DELETEâ”‚Pending/ â”‚
  â”‚      â”‚        â”‚         â”‚       â”‚         â”‚Complete â”‚
  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.3 Conflict Resolution

```
Scenario: Same object written in two regions simultaneously

Region EU writes "photo.jpg" v=A at T=100
Region US writes "photo.jpg" v=B at T=101

Conflict detection via vector clocks:
  EU version: {EU:1, US:0} â†’ "photo.jpg" = data_A
  US version: {EU:0, US:1} â†’ "photo.jpg" = data_B

Neither dominates â†’ CONFLICT

Resolution strategies (configurable per bucket):
  1. Last-Write-Wins (LWW) â€” timestamp-based, simplest
     â†’ US wins (T=101 > T=100)

  2. Source-Priority â€” designated primary region wins
     â†’ EU wins (EU is primary for "photos" bucket)

  3. Merge â€” application-specific (for structured data)
     â†’ Both versions kept, client resolves

  4. Custom webhook â€” call external resolver
     â†’ POST /resolve with both versions, get winner

Conflict metadata:
  {
    "key": "photo.jpg",
    "conflict_id": "uuid",
    "versions": [
      {"region": "EU", "version_id": "...", "timestamp": 100, "size": 1024},
      {"region": "US", "version_id": "...", "timestamp": 101, "size": 2048}
    ],
    "resolved_by": "LWW",
    "winner": "US"
  }
```

### 10.4 Geo-Aware Routing

```go
// GeoDNS or application-level routing
type GeoRouter struct {
    regions  map[string]RegionEndpoint
    fallback string
}

// Route read requests to nearest region
func (g *GeoRouter) RouteRead(clientIP net.IP, bucket, key string) string {
    // 1. Check if object has region affinity
    affinity := g.getRegionAffinity(bucket, key)
    if affinity != "" {
        return g.regions[affinity].Endpoint
    }

    // 2. Find nearest region by GeoIP
    clientRegion := g.geoIP.Lookup(clientIP)
    nearest := g.findNearest(clientRegion)

    // 3. Check if nearest region has the data
    if g.regionHasObject(nearest, bucket, key) {
        return g.regions[nearest].Endpoint
    }

    // 4. Fallback to primary region
    return g.regions[g.getPrimaryRegion(bucket)].Endpoint
}

// Route write requests based on bucket policy
func (g *GeoRouter) RouteWrite(bucket string) string {
    // Writes always go to the primary region for the bucket
    // Replication handles cross-region distribution
    return g.regions[g.getPrimaryRegion(bucket)].Endpoint
}
```

---

## 11. Replication, Backup & Mirror

### 11.1 Backup Targets

```
OpenEndpoint can back up to multiple target types:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenEndpoint Cluster                                â”‚
â”‚                                                     â”‚
â”‚  Backup Agent                                       â”‚
â”‚  â”œâ”€â”€ Schedule: daily 02:00 UTC                      â”‚
â”‚  â”œâ”€â”€ Type: incremental (only changed objects)       â”‚
â”‚  â”œâ”€â”€ Compression: zstd (level 3)                    â”‚
â”‚  â””â”€â”€ Encryption: AES-256-GCM                        â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ Change   â”‚ â† tracks all mutations since last     â”‚
â”‚  â”‚ Journal  â”‚   backup via sequence numbers          â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚       â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º AWS S3 (any region)
        â”‚            â””â”€â”€ s3://backup-bucket/openep/...
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Google Cloud Storage
        â”‚            â””â”€â”€ gs://backup-bucket/openep/...
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Azure Blob Storage
        â”‚            â””â”€â”€ az://container/openep/...
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Another OpenEndpoint Cluster
        â”‚            â””â”€â”€ https://backup.openep.example.com
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º NFS / Local Filesystem
        â”‚            â””â”€â”€ /mnt/backup/openep/...
        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º SFTP / Rsync Target
                     â””â”€â”€ sftp://backup.example.com/openep/...
```

### 11.2 Backup Format

```
Backup Structure:
backup-2024-01-15T020000Z/
â”œâ”€â”€ manifest.json           # backup metadata
â”‚   {
â”‚     "backup_id": "uuid",
â”‚     "timestamp": "2024-01-15T02:00:00Z",
â”‚     "type": "incremental",
â”‚     "base_backup": "uuid-of-last-full",
â”‚     "sequence_range": [10000, 15000],
â”‚     "object_count": 5000,
â”‚     "total_size": "50GB",
â”‚     "compressed_size": "35GB",
â”‚     "checksum": "sha256:abc..."
â”‚   }
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ buckets.jsonl       # bucket metadata (JSON lines)
â”‚   â””â”€â”€ objects.jsonl       # object metadata (JSON lines)
â””â”€â”€ data/
    â”œâ”€â”€ chunk-0001.zst      # compressed data chunks (256MB each)
    â”œâ”€â”€ chunk-0002.zst
    â””â”€â”€ chunk-0003.zst

Restore:
  openep backup restore --from s3://backup-bucket/openep/backup-2024-01-15T020000Z
  â†’ Downloads manifest â†’ validates checksums â†’ restores metadata â†’ restores data
  â†’ Point-in-time recovery: restore to any backup snapshot
```

### 11.3 Mirror Mode (Continuous Replication)

```
Mirror = real-time, continuous replication to another system.
Different from backup: mirror is always up-to-date, backup is periodic.

Source Cluster                    Mirror Target
  â”‚                                    â”‚
  â”‚  Every write operation:            â”‚
  â”‚  PUT, DELETE, versioning change    â”‚
  â”‚         â”‚                          â”‚
  â”‚         â–¼                          â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
  â”‚  â”‚ Mirror Agent  â”‚                 â”‚
  â”‚  â”‚               â”‚                 â”‚
  â”‚  â”‚ â€¢ Tail the    â”‚                 â”‚
  â”‚  â”‚   change log  â”‚                 â”‚
  â”‚  â”‚ â€¢ Batch       â”‚                 â”‚
  â”‚  â”‚   changes     â”‚                 â”‚
  â”‚  â”‚ â€¢ Stream to   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚  â”‚   target      â”‚  Replicate ops  â”‚
  â”‚  â”‚ â€¢ Track lag   â”‚                 â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
  â”‚                                    â”‚
  â”‚  Mirror lag target: < 60 seconds   â”‚
  â”‚                                    â”‚

Configuration:
  mirror:
    enabled: true
    targets:
      - name: "disaster-recovery"
        endpoint: "https://dr.openep.example.com"
        access_key: "mirror-user"
        secret_key: "..."
        buckets: ["*"]                # mirror all buckets
        mode: "async"                 # async | sync
        max_lag: "60s"
        bandwidth_limit: "100MB/s"
        compress: true
      - name: "analytics-copy"
        endpoint: "s3://analytics-bucket"
        buckets: ["logs-*", "events-*"]
        mode: "async"
        max_lag: "5m"
```

---

## 12. CDN Integration & Edge

### 12.1 CDN Architecture

```
OpenEndpoint serves as CDN origin:

                     User Request
                          â”‚
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  CDN Edge   â”‚
                   â”‚   (PoP)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                       â”‚
         Cache HIT                Cache MISS
              â”‚                       â”‚
              â–¼                       â–¼
         Return cached         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         content               â”‚ OpenEndpoint â”‚
                               â”‚   Origin     â”‚
                               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                               Return content
                               + Cache-Control
                               headers

Supported CDN Providers (via standard HTTP):
  â€¢ Cloudflare
  â€¢ AWS CloudFront
  â€¢ Fastly
  â€¢ Bunny CDN
  â€¢ Akamai
  â€¢ Any HTTP-based CDN
```

### 12.2 CDN-Optimized Endpoints

```go
// Dedicated CDN origin endpoints with optimized headers
router.Route("/cdn/v1", func(r chi.Router) {
    r.Use(CDNOriginMiddleware) // adds Cache-Control, ETag, etc.
    r.Get("/{bucket}/{key:.*}", CDNGetObject)
})

func CDNOriginMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Origin shield: accept X-Forwarded-For from CDN
        // Set aggressive cache headers for CDN
        // Support conditional requests (If-None-Match, If-Modified-Since)
        next.ServeHTTP(w, r)
    })
}

func CDNGetObject(w http.ResponseWriter, r *http.Request) {
    // 1. Check conditional request
    if etag := r.Header.Get("If-None-Match"); etag != "" {
        if objectETag == etag {
            w.WriteHeader(http.StatusNotModified)
            return
        }
    }

    // 2. Set CDN-friendly headers
    w.Header().Set("Cache-Control", getCacheControl(bucket, key))
    w.Header().Set("ETag", `"`+objectMeta.ETag+`"`)
    w.Header().Set("Last-Modified", objectMeta.CreatedAt.Format(http.TimeFormat))
    w.Header().Set("Accept-Ranges", "bytes")

    // 3. Support range requests (for video streaming etc.)
    if rangeHeader := r.Header.Get("Range"); rangeHeader != "" {
        serveRangeRequest(w, r, objectMeta)
        return
    }

    // 4. Serve full object
    http.ServeContent(w, r, key, objectMeta.CreatedAt, objectReader)
}
```

### 12.3 Presigned URLs for CDN

```
Flow: Client requests access â†’ Server generates presigned URL â†’ Client uses CDN

  Client                  API Server              CDN
    â”‚                         â”‚                    â”‚
    â”‚ POST /api/files/xyz     â”‚                    â”‚
    â”‚ "I want to view xyz"    â”‚                    â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                    â”‚
    â”‚                         â”‚                    â”‚
    â”‚  Generate presigned URL:â”‚                    â”‚
    â”‚  cdn.example.com/       â”‚                    â”‚
    â”‚    bucket/key?           â”‚                    â”‚
    â”‚    X-Amz-Expires=3600   â”‚                    â”‚
    â”‚    &X-Amz-Signature=... â”‚                    â”‚
    â”‚                         â”‚                    â”‚
    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                    â”‚
    â”‚ {url: "https://cdn..."}  â”‚                    â”‚
    â”‚                         â”‚                    â”‚
    â”‚ GET cdn.example.com/... â”‚                    â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
    â”‚                         â”‚   Cache MISS        â”‚
    â”‚                         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                         â”‚   Verify signature  â”‚
    â”‚                         â”‚   Return object     â”‚
    â”‚                         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
    â”‚                         â”‚   CDN caches         â”‚
    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚  Content delivered       â”‚                    â”‚

Next request for same URL:
    â”‚ GET cdn.example.com/... â”‚                    â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
    â”‚                         â”‚   Cache HIT!        â”‚
    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚  Instant delivery        â”‚    (no origin)     â”‚
```

### 12.4 Cache Invalidation API

```go
// When an object is updated or deleted, invalidate CDN cache
type CDNManager struct {
    providers []CDNProvider
}

type CDNProvider interface {
    Invalidate(ctx context.Context, paths []string) error
    PurgeAll(ctx context.Context) error
}

// Cloudflare implementation
type CloudflareCDN struct {
    zoneID string
    apiKey string
}

func (c *CloudflareCDN) Invalidate(ctx context.Context, paths []string) error {
    // POST https://api.cloudflare.com/client/v4/zones/{zone}/purge_cache
    // {"files": ["https://cdn.example.com/bucket/key1", ...]}
}

// Hook into object lifecycle
func (s *ObjectService) afterPut(bucket, key string) {
    if s.cdn != nil {
        go s.cdn.Invalidate(context.Background(), []string{
            fmt.Sprintf("/%s/%s", bucket, key),
        })
    }
}
```

---

## 13. Web Dashboard (Next.js)

### 13.1 Repository: github.com/OpenEndpoint/dashboard

```
Technology Stack:
  â€¢ Next.js 15 (App Router)
  â€¢ React 19
  â€¢ TypeScript 5
  â€¢ Tailwind CSS v4
  â€¢ shadcn/ui components
  â€¢ TanStack Query (data fetching)
  â€¢ TanStack Table (data grids)
  â€¢ Recharts (analytics charts)
  â€¢ Monaco Editor (config editing)
  â€¢ next-intl (i18n)
```

### 13.2 Dashboard Pages & Features

```
Page Map:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Dashboard (/)
â”œâ”€â”€ Cluster health overview (nodes, regions)
â”œâ”€â”€ Storage usage gauge (total/used/available)
â”œâ”€â”€ Request rate chart (puts/gets/deletes per second)
â”œâ”€â”€ Bandwidth chart (ingress/egress)
â”œâ”€â”€ Top buckets by size
â”œâ”€â”€ Recent errors/alerts
â””â”€â”€ Quick actions (create bucket, upload file)

ğŸª£ Buckets (/buckets)
â”œâ”€â”€ List all buckets with stats (size, object count, created)
â”œâ”€â”€ Search/filter buckets
â”œâ”€â”€ Create new bucket (modal)
â”‚   â”œâ”€â”€ Name, region, versioning toggle
â”‚   â””â”€â”€ Lifecycle rules (visual builder)
â”œâ”€â”€ Bucket detail (/buckets/{name})
â”‚   â”œâ”€â”€ Object browser (file explorer UI)
â”‚   â”‚   â”œâ”€â”€ Navigate "directories" (delimiter-based)
â”‚   â”‚   â”œâ”€â”€ Upload files (drag & drop, multipart)
â”‚   â”‚   â”œâ”€â”€ Download files
â”‚   â”‚   â”œâ”€â”€ Delete files (with confirmation)
â”‚   â”‚   â”œâ”€â”€ Preview files (images, text, JSON, video)
â”‚   â”‚   â”œâ”€â”€ Copy/move files
â”‚   â”‚   â”œâ”€â”€ Generate presigned URLs
â”‚   â”‚   â””â”€â”€ View object metadata + versions
â”‚   â”œâ”€â”€ Bucket settings
â”‚   â”‚   â”œâ”€â”€ Versioning (enable/suspend)
â”‚   â”‚   â”œâ”€â”€ Lifecycle rules (visual editor)
â”‚   â”‚   â”œâ”€â”€ CORS configuration
â”‚   â”‚   â”œâ”€â”€ Replication rules (v3)
â”‚   â”‚   â””â”€â”€ Access policy (v4)
â”‚   â””â”€â”€ Bucket analytics
â”‚       â”œâ”€â”€ Storage growth over time
â”‚       â”œâ”€â”€ Request patterns
â”‚       â””â”€â”€ Top accessed objects

ğŸ–¥ï¸ Nodes (/nodes) â€” v2+
â”œâ”€â”€ Cluster topology visualization
â”‚   â””â”€â”€ Interactive node map with health indicators
â”œâ”€â”€ Node list with status, capacity, last seen
â”œâ”€â”€ Node detail (/nodes/{id})
â”‚   â”œâ”€â”€ CPU, memory, disk, network charts
â”‚   â”œâ”€â”€ Objects stored, replication status
â”‚   â””â”€â”€ Logs viewer (streaming)
â”œâ”€â”€ Add node wizard
â””â”€â”€ Remove node (with drain/rebalance)

ğŸŒ Regions (/regions) â€” v3+
â”œâ”€â”€ World map with region markers
â”œâ”€â”€ Replication status between regions
â”‚   â””â”€â”€ Replication lag gauges
â”œâ”€â”€ Region detail
â”‚   â”œâ”€â”€ Cluster health
â”‚   â”œâ”€â”€ Cross-region bandwidth usage
â”‚   â””â”€â”€ Replication policy editor
â””â”€â”€ Add region wizard

ğŸ’¾ Backups (/backups) â€” v2+
â”œâ”€â”€ Backup schedule overview
â”œâ”€â”€ Backup history (timeline)
â”œâ”€â”€ Create backup (manual trigger)
â”œâ”€â”€ Restore wizard
â”‚   â”œâ”€â”€ Select backup
â”‚   â”œâ”€â”€ Choose target (same cluster / new cluster)
â”‚   â”œâ”€â”€ Preview changes
â”‚   â””â”€â”€ Execute restore
â””â”€â”€ Backup target management
    â”œâ”€â”€ Add S3/GCS/Azure/NFS target
    â””â”€â”€ Test connectivity

ğŸ”‘ Access Management (/access)
â”œâ”€â”€ v1: API key management
â”‚   â”œâ”€â”€ Create/revoke access keys
â”‚   â””â”€â”€ Key permissions (per-bucket)
â”œâ”€â”€ v4: Full IAM
â”‚   â”œâ”€â”€ Users (/access/users)
â”‚   â”œâ”€â”€ Groups (/access/groups)
â”‚   â”œâ”€â”€ Policies (/access/policies)
â”‚   â”‚   â””â”€â”€ Visual policy builder
â”‚   â””â”€â”€ Audit log (/access/audit)

ğŸ“ˆ Analytics (/analytics) â€” v3+
â”œâ”€â”€ Storage analytics
â”‚   â”œâ”€â”€ Growth trends
â”‚   â”œâ”€â”€ Cost estimation
â”‚   â””â”€â”€ Storage class distribution
â”œâ”€â”€ Traffic analytics
â”‚   â”œâ”€â”€ Request heatmap (time Ã— bucket)
â”‚   â”œâ”€â”€ Geographic request distribution
â”‚   â”œâ”€â”€ Bandwidth by region
â”‚   â””â”€â”€ Error rate trends
â”œâ”€â”€ Performance analytics
â”‚   â”œâ”€â”€ Latency percentiles (p50, p95, p99)
â”‚   â”œâ”€â”€ Throughput over time
â”‚   â””â”€â”€ Backend comparison (flat vs packed)
â””â”€â”€ Capacity planning
    â”œâ”€â”€ Projected growth
    â””â”€â”€ Scaling recommendations

âš™ï¸ Settings (/settings)
â”œâ”€â”€ Cluster configuration (YAML editor with Monaco)
â”œâ”€â”€ Network settings (TLS, ports, domains)
â”œâ”€â”€ Storage backend configuration
â”œâ”€â”€ Notification channels (email, Slack, webhook)
â”œâ”€â”€ CDN configuration
â”œâ”€â”€ Maintenance mode toggle
â””â”€â”€ System info (version, license, uptime)

ğŸ” Explorer (/explorer)
â”œâ”€â”€ S3 API explorer (like Swagger/OpenAPI UI)
â”‚   â”œâ”€â”€ Try any S3 operation interactively
â”‚   â”œâ”€â”€ Generate code snippets (Go, Python, JS, curl)
â”‚   â””â”€â”€ View request/response with headers
â””â”€â”€ Connection helper
    â”œâ”€â”€ Generate config for aws-cli
    â”œâ”€â”€ Generate config for s3cmd
    â”œâ”€â”€ Generate SDK initialization code
    â””â”€â”€ Test connection button
```

### 13.3 Dashboard Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js Dashboard                                      â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  App Router (RSC + Client Components)             â”‚  â”‚
â”‚  â”‚                                                    â”‚  â”‚
â”‚  â”‚  Server Components:                               â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ Layout (navigation, auth check)              â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ Dashboard page (initial data fetch)          â”‚  â”‚
â”‚  â”‚  â””â”€â”€ Settings page (config loading)               â”‚  â”‚
â”‚  â”‚                                                    â”‚  â”‚
â”‚  â”‚  Client Components:                               â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ ObjectBrowser (interactive file explorer)    â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ UploadDropzone (drag & drop + progress)     â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ ClusterMap (D3.js topology visualization)   â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ MetricsCharts (Recharts, real-time)         â”‚  â”‚
â”‚  â”‚  â””â”€â”€ PolicyBuilder (visual IAM policy editor)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                              â”‚
â”‚                          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  API Client Layer                                 â”‚  â”‚
â”‚  â”‚                                                    â”‚  â”‚
â”‚  â”‚  TanStack Query hooks:                            â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ useBuckets()                                 â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ useObjects(bucket, prefix)                   â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ useClusterHealth()                           â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ useMetrics(timeRange)                        â”‚  â”‚
â”‚  â”‚  â””â”€â”€ useRealtimeEvents() â† WebSocket              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  OpenEndpoint API       â”‚
              â”‚                        â”‚
              â”‚  S3 API (:9000)        â”‚ â† bucket/object operations
              â”‚  Management API (:9001)â”‚ â† cluster, metrics, config
              â”‚  WebSocket (:9001/ws)  â”‚ â† real-time events
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 13.4 Management API (non-S3)

```
OpenEndpoint exposes a management API alongside the S3 API:

GET    /api/v1/status                    # cluster health
GET    /api/v1/metrics                   # prometheus-format metrics
GET    /api/v1/config                    # current configuration

GET    /api/v1/nodes                     # list nodes
GET    /api/v1/nodes/{id}               # node details
POST   /api/v1/nodes/{id}/drain         # drain node
DELETE /api/v1/nodes/{id}               # remove node

GET    /api/v1/regions                   # list regions
POST   /api/v1/regions                   # add region
GET    /api/v1/regions/{id}/status       # replication status

POST   /api/v1/backups                   # trigger backup
GET    /api/v1/backups                   # list backups
POST   /api/v1/backups/{id}/restore     # restore from backup

GET    /api/v1/access/keys              # list API keys
POST   /api/v1/access/keys              # create API key
DELETE /api/v1/access/keys/{id}         # revoke API key

WS     /api/v1/events                    # real-time event stream
  Events:
    object.created, object.deleted,
    node.joined, node.left, node.unhealthy,
    backup.started, backup.completed,
    replication.lag_warning,
    lifecycle.objects_expired
```

### 13.5 Object Browser UX

```
File Explorer-style interface:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸª£ my-bucket  /  images  /  2024  /                        â”‚
â”‚  â† Back    ğŸ“¤ Upload    ğŸ“ New Folder    ğŸ—‘ï¸ Delete Selected  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â˜  Name              Size      Modified         Actions    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â˜  ğŸ“ thumbnails/    â€”         2024-01-10       â†’          â”‚
â”‚  â˜  ğŸ“ originals/     â€”         2024-01-10       â†’          â”‚
â”‚  â˜  ğŸ–¼ï¸ hero.jpg       2.4 MB    2024-01-15 14:30 â‹®         â”‚
â”‚  â˜  ğŸ–¼ï¸ banner.png     856 KB    2024-01-14 09:15 â‹®         â”‚
â”‚  â˜  ğŸ“„ metadata.json  1.2 KB    2024-01-13 11:00 â‹®         â”‚
â”‚                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
â”‚  Page 1 of 5    â—€ Previous  Next â–¶    1000 objects          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€ Upload Zone â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚   ğŸ“ Drag & drop files here, or click to browse        â”‚ â”‚
â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚   Uploading: hero-large.jpg  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 78%  12MB/s    â”‚ â”‚
â”‚  â”‚   Queued: 3 files (45 MB total)                        â”‚ â”‚
â”‚  â”‚                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Object Detail Panel (click on object):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  hero.jpg                                          âœ• Close  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚                                    â”‚                     â”‚
â”‚  â”‚        [Image Preview]             â”‚                     â”‚
â”‚  â”‚                                    â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                             â”‚
â”‚  Key:          images/2024/hero.jpg                         â”‚
â”‚  Size:         2.4 MB                                       â”‚
â”‚  Content-Type: image/jpeg                                   â”‚
â”‚  ETag:         "d41d8cd98f00b204e9800998ecf8427e"          â”‚
â”‚  Last Modified: 2024-01-15 14:30:00 UTC                    â”‚
â”‚  Version ID:   01945a2e-7b3f-7abc-8def-1234567890ab        â”‚
â”‚                                                             â”‚
â”‚  Custom Metadata:                                           â”‚
â”‚  x-amz-meta-author: alice                                   â”‚
â”‚  x-amz-meta-project: website-redesign                       â”‚
â”‚                                                             â”‚
â”‚  Versions:                                                  â”‚
â”‚  â”œâ”€â”€ v3 (current) â€” 2024-01-15 â€” 2.4 MB                   â”‚
â”‚  â”œâ”€â”€ v2           â€” 2024-01-10 â€” 2.1 MB                   â”‚
â”‚  â””â”€â”€ v1           â€” 2024-01-05 â€” 1.8 MB                   â”‚
â”‚                                                             â”‚
â”‚  [Download]  [Share Link]  [Copy URL]  [Delete]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 14. CLI Tool

### 14.1 CLI Design: `openep`

```bash
# Installation
curl -fsSL https://get.openendpoint.com | sh
# or
go install github.com/OpenEndpoint/openendpoint/cmd/openep@latest

# Configuration
openep config set endpoint http://localhost:9000
openep config set access-key admin
openep config set secret-key changeme

# Bucket operations
openep bucket create my-bucket
openep bucket create my-bucket --versioning enabled
openep bucket list
openep bucket info my-bucket
openep bucket delete my-bucket

# Object operations
openep put my-bucket/photos/cat.jpg ./cat.jpg
openep get my-bucket/photos/cat.jpg ./downloaded-cat.jpg
openep ls my-bucket/photos/
openep ls my-bucket/photos/ --recursive --human-readable
openep rm my-bucket/photos/cat.jpg
openep rm my-bucket/photos/ --recursive --force

# Bulk operations
openep sync ./local-dir/ my-bucket/prefix/ --delete
openep cp my-bucket/source/ my-bucket/dest/ --recursive
openep mv my-bucket/old-name.jpg my-bucket/new-name.jpg

# Presigned URLs
openep presign my-bucket/photos/cat.jpg --expires 1h
openep presign my-bucket/uploads/data.csv --method PUT --expires 30m

# Versioning
openep versions my-bucket/photos/cat.jpg
openep get my-bucket/photos/cat.jpg --version-id abc123

# Cluster management (v2+)
openep cluster status
openep cluster nodes
openep cluster join 10.0.1.5:9002
openep cluster drain node-03
openep cluster rebalance --status

# Region management (v3+)
openep region list
openep region add eu-west --endpoint https://eu.openep.example.com
openep region status
openep region replication-lag

# Backup (v2+)
openep backup create --target s3://backup-bucket
openep backup list
openep backup restore backup-2024-01-15T020000Z
openep backup schedule --cron "0 2 * * *" --target s3://backup-bucket

# Server
openep server start
openep server start --config /etc/openendpoint/config.yaml
openep server start --data-dir /var/lib/openendpoint
```

### 14.2 CLI Output Design

```bash
$ openep cluster status

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  OpenEndpoint Cluster Status                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Cluster:    production
  Nodes:      5/5 healthy
  Regions:    3 (eu-west, us-east, ap-south)
  Storage:    12.4 TB used / 50 TB total (24.8%)
  Objects:    847,293,412
  Uptime:     45d 12h 30m

  Nodes:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Node       â”‚ Region   â”‚ Status    â”‚ Storage    â”‚ Objects â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ node-01    â”‚ eu-west  â”‚ â— Active  â”‚ 2.5/10 TB  â”‚ 169M    â”‚
  â”‚ node-02    â”‚ eu-west  â”‚ â— Active  â”‚ 2.4/10 TB  â”‚ 168M    â”‚
  â”‚ node-03    â”‚ us-east  â”‚ â— Active  â”‚ 2.6/10 TB  â”‚ 171M    â”‚
  â”‚ node-04    â”‚ us-east  â”‚ â— Active  â”‚ 2.5/10 TB  â”‚ 170M    â”‚
  â”‚ node-05    â”‚ ap-south â”‚ â— Active  â”‚ 2.4/10 TB  â”‚ 169M    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Replication:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Route            â”‚ Lag   â”‚ Status  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ eu-west â†’ us-eastâ”‚ 12s   â”‚ â— OK    â”‚
  â”‚ eu-west â†’ ap-southâ”‚ 45s  â”‚ â— OK    â”‚
  â”‚ us-east â†’ ap-southâ”‚ 30s  â”‚ â— OK    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 15. Observability & Monitoring

### 15.1 Metrics (Prometheus)

```
# Storage metrics
openendpoint_storage_bytes_total{backend="flatfile|packed"} gauge
openendpoint_storage_bytes_used{backend="flatfile|packed"} gauge
openendpoint_storage_objects_total{bucket="..."} gauge

# Request metrics
openendpoint_http_requests_total{method, operation, status} counter
openendpoint_http_request_duration_seconds{method, operation} histogram
openendpoint_http_request_size_bytes{method} histogram
openendpoint_http_response_size_bytes{method} histogram

# Backend metrics
openendpoint_storage_put_duration_seconds{backend} histogram
openendpoint_storage_get_duration_seconds{backend} histogram
openendpoint_storage_delete_duration_seconds{backend} histogram

# Cluster metrics (v2)
openendpoint_cluster_nodes_total gauge
openendpoint_cluster_nodes_healthy gauge
openendpoint_replication_lag_seconds{source, target} gauge
openendpoint_replication_bytes_total{source, target} counter
openendpoint_rebalance_progress_ratio gauge

# Lifecycle metrics
openendpoint_lifecycle_objects_expired_total counter
openendpoint_lifecycle_bytes_freed_total counter

# Packed volume metrics
openendpoint_volume_count{state="active|sealed|compacting"} gauge
openendpoint_volume_compaction_duration_seconds histogram
openendpoint_volume_dead_bytes_ratio gauge

# Multipart metrics
openendpoint_multipart_uploads_active gauge
openendpoint_multipart_uploads_completed_total counter
openendpoint_multipart_uploads_aborted_total counter
```

### 15.2 Distributed Tracing

```
Integration with OpenTelemetry:

  PutObject trace:
  â”Œâ”€ HTTP Handler (50ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ â”Œâ”€ Auth: SigV4 Verify (2ms) â”€â”                        â”‚
  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
  â”‚ â”Œâ”€ Storage: Put (35ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
  â”‚ â”‚ â”Œâ”€ Hash computation (5ms) â”                    â”‚     â”‚
  â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚     â”‚
  â”‚ â”‚ â”Œâ”€ Disk write (25ms) â”€â”€â”€â”€â”€â”                    â”‚     â”‚
  â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚     â”‚
  â”‚ â”‚ â”Œâ”€ fsync (5ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚     â”‚
  â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚     â”‚
  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
  â”‚ â”Œâ”€ Metadata: Put (8ms) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
  â”‚ â”‚ â”Œâ”€ Pebble batch write (6ms) â”                 â”‚     â”‚
  â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚     â”‚
  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
  â”‚ â”Œâ”€ Replication: async (0ms, fire-and-forget) â”€â”€â”      â”‚
  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 15.3 Alerting Rules

```yaml
# Grafana/Prometheus alerting rules
groups:
  - name: openendpoint
    rules:
      - alert: HighErrorRate
        expr: rate(openendpoint_http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: critical

      - alert: DiskSpaceLow
        expr: openendpoint_storage_bytes_used / openendpoint_storage_bytes_total > 0.85
        for: 10m
        labels:
          severity: warning

      - alert: ReplicationLagHigh
        expr: openendpoint_replication_lag_seconds > 300
        for: 5m
        labels:
          severity: warning

      - alert: NodeUnhealthy
        expr: openendpoint_cluster_nodes_healthy < openendpoint_cluster_nodes_total
        for: 2m
        labels:
          severity: critical

      - alert: CompactionNeeded
        expr: openendpoint_volume_dead_bytes_ratio > 0.4
        for: 1h
        labels:
          severity: info
```

---

## 16. Security Architecture

### 16.1 Defense in Depth

```
Layer 1: Network
  â”œâ”€â”€ TLS 1.3 (mandatory in production)
  â”œâ”€â”€ mTLS between cluster nodes
  â”œâ”€â”€ Network segmentation (management API on separate port)
  â””â”€â”€ Rate limiting (per-IP token bucket)

Layer 2: Authentication
  â”œâ”€â”€ AWS Signature V4 (S3 API)
  â”œâ”€â”€ API keys (Management API)
  â”œâ”€â”€ OIDC / LDAP integration (v4)
  â””â”€â”€ Short-lived tokens for dashboard

Layer 3: Authorization
  â”œâ”€â”€ Per-bucket access control (v1)
  â”œâ”€â”€ IAM policies (v4)
  â”œâ”€â”€ Resource-based policies (v4)
  â””â”€â”€ Principle of least privilege

Layer 4: Data Protection
  â”œâ”€â”€ At-rest encryption: AES-256-GCM (v4)
  â”œâ”€â”€ In-transit encryption: TLS 1.3
  â”œâ”€â”€ Key management: integrated KMS or external (Vault)
  â”œâ”€â”€ Object Lock / WORM (v4)
  â””â”€â”€ Secure deletion (overwrite on delete, optional)

Layer 5: Audit & Compliance
  â”œâ”€â”€ Immutable audit log (all API calls)
  â”œâ”€â”€ Access logs (S3-compatible format)
  â”œâ”€â”€ Data residency enforcement (v3)
  â””â”€â”€ Compliance reports (GDPR, HIPAA markers)
```

### 16.2 Input Validation

```go
// Bucket name validation (S3 rules)
func validateBucketName(name string) error {
    if len(name) < 3 || len(name) > 63 {
        return ErrInvalidBucketName
    }
    if !regexp.MustCompile(`^[a-z0-9][a-z0-9.-]*[a-z0-9]$`).MatchString(name) {
        return ErrInvalidBucketName
    }
    if strings.Contains(name, "..") {
        return ErrInvalidBucketName
    }
    if net.ParseIP(name) != nil {
        return ErrInvalidBucketName // no IP-format names
    }
    return nil
}

// Object key validation
func validateObjectKey(key string) error {
    if len(key) == 0 || len(key) > 1024 {
        return ErrInvalidObjectKey
    }
    // Prevent path traversal
    if strings.Contains(key, "..") {
        return ErrInvalidObjectKey
    }
    // No null bytes
    if strings.ContainsRune(key, 0) {
        return ErrInvalidObjectKey
    }
    return nil
}
```

---

## 17. Performance Engineering

### 17.1 Performance Targets by Version

| Metric | v1 (Single) | v2 (Cluster) | v3 (Multi-Region) |
|--------|-------------|-------------|-------------------|
| PUT/s (1MB) | 5,000 | 15,000 | 10,000 (per region) |
| GET/s (1MB) | 10,000 | 30,000 | 20,000 (per region) |
| PUT p99 latency | < 10ms | < 15ms | < 20ms (local) |
| GET p99 latency | < 5ms | < 8ms | < 10ms (local) |
| List 1000 keys | < 20ms | < 30ms | < 30ms |
| Max object size | 5TB | 5TB | 5TB |
| Concurrent conns | 10,000 | 50,000 | 100,000 |

### 17.2 Optimization Techniques

```
1. Zero-copy I/O
   â”œâ”€â”€ sendfile(2) for GET responses (kernel â†’ socket, no userspace)
   â”œâ”€â”€ splice(2) for PUT data (socket â†’ file, no userspace)
   â””â”€â”€ mmap for packed volume index

2. Memory management
   â”œâ”€â”€ sync.Pool for buffer reuse (avoid GC pressure)
   â”œâ”€â”€ Pre-allocated byte buffers (32KB, 256KB, 1MB pools)
   â””â”€â”€ Arena allocation for request-scoped objects (Go 1.22+)

3. I/O optimization
   â”œâ”€â”€ O_DIRECT for large objects (bypass page cache)
   â”œâ”€â”€ io_uring for async I/O (Linux 5.1+, optional)
   â”œâ”€â”€ Batch fsync (group commit every 10ms)
   â””â”€â”€ AIO for concurrent reads from packed volumes

4. Network optimization
   â”œâ”€â”€ HTTP/2 for multiplexed connections
   â”œâ”€â”€ Keep-alive connection pooling
   â”œâ”€â”€ TCP_NODELAY for low-latency responses
   â””â”€â”€ SO_REUSEPORT for multi-listener

5. Metadata optimization
   â”œâ”€â”€ Pebble bloom filters (10-bit, <1% false positive)
   â”œâ”€â”€ Read-through cache (LRU, 10000 hot object metas)
   â”œâ”€â”€ Prefix compression in LSM tree
   â””â”€â”€ Dedicated WAL disk (separate from data)
```

---

## 18. Deployment & Operations

### 18.1 Deployment Options

```yaml
# 1. Single Binary
wget https://github.com/OpenEndpoint/openendpoint/releases/latest/download/openep-linux-amd64
chmod +x openep-linux-amd64
./openep-linux-amd64 server start

# 2. Docker
docker run -d \
  --name openendpoint \
  -p 9000:9000 \
  -p 9001:9001 \
  -v openep-data:/var/lib/openendpoint \
  openendpoint/openendpoint:latest

# 3. Docker Compose (cluster)
# docker-compose.yml
services:
  openep-1:
    image: openendpoint/openendpoint:latest
    environment:
      OPENEP_NODE_NAME: node-1
      OPENEP_CLUSTER_JOIN: openep-2:9002,openep-3:9002
    volumes:
      - node1-data:/var/lib/openendpoint
    ports:
      - "9000:9000"

  openep-2:
    image: openendpoint/openendpoint:latest
    environment:
      OPENEP_NODE_NAME: node-2
      OPENEP_CLUSTER_JOIN: openep-1:9002,openep-3:9002
    volumes:
      - node2-data:/var/lib/openendpoint

  openep-3:
    image: openendpoint/openendpoint:latest
    environment:
      OPENEP_NODE_NAME: node-3
      OPENEP_CLUSTER_JOIN: openep-1:9002,openep-2:9002
    volumes:
      - node3-data:/var/lib/openendpoint

# 4. Kubernetes (Helm)
helm repo add openendpoint https://charts.openendpoint.com
helm install my-storage openendpoint/openendpoint \
  --set cluster.nodes=5 \
  --set storage.size=100Gi \
  --set storage.backend=packed

# 5. Ansible Playbook (bare metal)
ansible-playbook openendpoint.yml -i inventory.ini
```

### 18.2 Kubernetes Architecture

```yaml
# Helm chart structure
openendpoint/
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ values.yaml
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ statefulset.yaml      # OpenEndpoint nodes
â”‚   â”œâ”€â”€ service.yaml          # S3 API service
â”‚   â”œâ”€â”€ service-mgmt.yaml    # Management API service
â”‚   â”œâ”€â”€ ingress.yaml          # S3 + Dashboard ingress
â”‚   â”œâ”€â”€ configmap.yaml        # Configuration
â”‚   â”œâ”€â”€ secret.yaml           # Credentials
â”‚   â”œâ”€â”€ pvc.yaml              # Persistent volumes
â”‚   â”œâ”€â”€ pdb.yaml              # Pod disruption budget
â”‚   â”œâ”€â”€ hpa.yaml              # Horizontal pod autoscaler
â”‚   â”œâ”€â”€ servicemonitor.yaml   # Prometheus ServiceMonitor
â”‚   â””â”€â”€ dashboard/
â”‚       â”œâ”€â”€ deployment.yaml   # Dashboard (Next.js)
â”‚       â””â”€â”€ service.yaml
```

---

## 19. SDK & Developer Experience

### 19.1 Official SDKs (Future)

```
While any S3 SDK works, official SDKs add OpenEndpoint-specific features:

github.com/OpenEndpoint/sdk-go       # Go SDK
github.com/OpenEndpoint/sdk-js       # JavaScript/TypeScript SDK
github.com/OpenEndpoint/sdk-python   # Python SDK

Features beyond standard S3:
  â€¢ Cluster management operations
  â€¢ Real-time event subscriptions (WebSocket)
  â€¢ Presigned URL helpers
  â€¢ Multipart upload with automatic chunking
  â€¢ Retry with exponential backoff + jitter
  â€¢ Connection pooling
```

### 19.2 Developer Onboarding

```bash
# 30-second quickstart
docker run -d -p 9000:9000 -p 9001:9001 openendpoint/openendpoint

# Use with aws-cli (zero config on OpenEndpoint side)
aws --endpoint-url http://localhost:9000 s3 mb s3://my-bucket
aws --endpoint-url http://localhost:9000 s3 cp file.txt s3://my-bucket/
aws --endpoint-url http://localhost:9000 s3 ls s3://my-bucket/

# Dashboard available at http://localhost:9001
```

---

## 20. Repository Structure

```
GitHub Organization: github.com/OpenEndpoint
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Repo 1: openendpoint/openendpoint (Core)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  The Go server â€” single binary, all features.

  openendpoint/
  â”œâ”€â”€ cmd/
  â”‚   â”œâ”€â”€ openep/                      # CLI + server binary
  â”‚   â”‚   â”œâ”€â”€ main.go
  â”‚   â”‚   â””â”€â”€ commands/
  â”‚   â”‚       â”œâ”€â”€ server.go            # openep server start
  â”‚   â”‚       â”œâ”€â”€ bucket.go            # openep bucket create
  â”‚   â”‚       â”œâ”€â”€ object.go            # openep put/get/ls/rm
  â”‚   â”‚       â”œâ”€â”€ cluster.go           # openep cluster status
  â”‚   â”‚       â”œâ”€â”€ region.go            # openep region list
  â”‚   â”‚       â”œâ”€â”€ backup.go            # openep backup create
  â”‚   â”‚       â””â”€â”€ config.go            # openep config set
  â”‚   â””â”€â”€ openep-gateway/             # CDN origin gateway (v3)
  â”‚
  â”œâ”€â”€ internal/
  â”‚   â”œâ”€â”€ api/                         # S3 HTTP handlers
  â”‚   â”‚   â”œâ”€â”€ router.go
  â”‚   â”‚   â”œâ”€â”€ bucket_handler.go
  â”‚   â”‚   â”œâ”€â”€ object_handler.go
  â”‚   â”‚   â”œâ”€â”€ multipart_handler.go
  â”‚   â”‚   â”œâ”€â”€ versioning_handler.go
  â”‚   â”‚   â”œâ”€â”€ lifecycle_handler.go
  â”‚   â”‚   â”œâ”€â”€ presign.go
  â”‚   â”‚   â”œâ”€â”€ response.go
  â”‚   â”‚   â””â”€â”€ errors.go
  â”‚   â”‚
  â”‚   â”œâ”€â”€ mgmt/                        # Management API
  â”‚   â”‚   â”œâ”€â”€ router.go
  â”‚   â”‚   â”œâ”€â”€ status.go
  â”‚   â”‚   â”œâ”€â”€ nodes.go
  â”‚   â”‚   â”œâ”€â”€ regions.go
  â”‚   â”‚   â”œâ”€â”€ backups.go
  â”‚   â”‚   â”œâ”€â”€ access.go
  â”‚   â”‚   â””â”€â”€ websocket.go            # real-time events
  â”‚   â”‚
  â”‚   â”œâ”€â”€ auth/
  â”‚   â”‚   â”œâ”€â”€ sigv4.go
  â”‚   â”‚   â”œâ”€â”€ sigv4_test.go
  â”‚   â”‚   â”œâ”€â”€ presign.go
  â”‚   â”‚   â”œâ”€â”€ credentials.go
  â”‚   â”‚   â””â”€â”€ iam/                     # v4
  â”‚   â”‚       â”œâ”€â”€ policy.go
  â”‚   â”‚       â”œâ”€â”€ evaluator.go
  â”‚   â”‚       â””â”€â”€ store.go
  â”‚   â”‚
  â”‚   â”œâ”€â”€ engine/
  â”‚   â”‚   â”œâ”€â”€ service.go               # ObjectService
  â”‚   â”‚   â”œâ”€â”€ put.go
  â”‚   â”‚   â”œâ”€â”€ get.go
  â”‚   â”‚   â”œâ”€â”€ delete.go
  â”‚   â”‚   â”œâ”€â”€ list.go
  â”‚   â”‚   â”œâ”€â”€ copy.go
  â”‚   â”‚   â”œâ”€â”€ multipart.go
  â”‚   â”‚   â”œâ”€â”€ versioning.go
  â”‚   â”‚   â”œâ”€â”€ lifecycle.go
  â”‚   â”‚   â””â”€â”€ locker.go               # sharded per-object locking
  â”‚   â”‚
  â”‚   â”œâ”€â”€ storage/
  â”‚   â”‚   â”œâ”€â”€ backend.go               # interface
  â”‚   â”‚   â”œâ”€â”€ flatfile/
  â”‚   â”‚   â”‚   â”œâ”€â”€ flatfile.go
  â”‚   â”‚   â”‚   â”œâ”€â”€ flatfile_test.go
  â”‚   â”‚   â”‚   â””â”€â”€ directio.go          # O_DIRECT support
  â”‚   â”‚   â””â”€â”€ packed/
  â”‚   â”‚       â”œâ”€â”€ packed.go
  â”‚   â”‚       â”œâ”€â”€ volume.go
  â”‚   â”‚       â”œâ”€â”€ needle.go
  â”‚   â”‚       â”œâ”€â”€ index.go
  â”‚   â”‚       â”œâ”€â”€ wal.go
  â”‚   â”‚       â”œâ”€â”€ compactor.go
  â”‚   â”‚       â””â”€â”€ packed_test.go
  â”‚   â”‚
  â”‚   â”œâ”€â”€ metadata/
  â”‚   â”‚   â”œâ”€â”€ store.go                 # interface
  â”‚   â”‚   â”œâ”€â”€ types.go
  â”‚   â”‚   â”œâ”€â”€ pebble/
  â”‚   â”‚   â”‚   â”œâ”€â”€ pebble.go
  â”‚   â”‚   â”‚   â””â”€â”€ pebble_test.go
  â”‚   â”‚   â””â”€â”€ bbolt/
  â”‚   â”‚       â”œâ”€â”€ bbolt.go
  â”‚   â”‚       â””â”€â”€ bbolt_test.go
  â”‚   â”‚
  â”‚   â”œâ”€â”€ cluster/                     # v2
  â”‚   â”‚   â”œâ”€â”€ manager.go
  â”‚   â”‚   â”œâ”€â”€ gossip.go
  â”‚   â”‚   â”œâ”€â”€ hashring.go
  â”‚   â”‚   â”œâ”€â”€ replicator.go
  â”‚   â”‚   â”œâ”€â”€ rebalancer.go
  â”‚   â”‚   â”œâ”€â”€ repair.go               # read repair + anti-entropy
  â”‚   â”‚   â””â”€â”€ local.go                # v1 stub
  â”‚   â”‚
  â”‚   â”œâ”€â”€ federation/                  # v3
  â”‚   â”‚   â”œâ”€â”€ manager.go
  â”‚   â”‚   â”œâ”€â”€ replication.go
  â”‚   â”‚   â”œâ”€â”€ conflict.go
  â”‚   â”‚   â”œâ”€â”€ geo_router.go
  â”‚   â”‚   â””â”€â”€ bandwidth.go
  â”‚   â”‚
  â”‚   â”œâ”€â”€ backup/                      # v2
  â”‚   â”‚   â”œâ”€â”€ engine.go
  â”‚   â”‚   â”œâ”€â”€ snapshot.go
  â”‚   â”‚   â”œâ”€â”€ restore.go
  â”‚   â”‚   â”œâ”€â”€ mirror.go
  â”‚   â”‚   â””â”€â”€ targets/
  â”‚   â”‚       â”œâ”€â”€ s3.go
  â”‚   â”‚       â”œâ”€â”€ gcs.go
  â”‚   â”‚       â”œâ”€â”€ azure.go
  â”‚   â”‚       â”œâ”€â”€ nfs.go
  â”‚   â”‚       â””â”€â”€ sftp.go
  â”‚   â”‚
  â”‚   â”œâ”€â”€ cdn/                         # v3
  â”‚   â”‚   â”œâ”€â”€ handler.go
  â”‚   â”‚   â”œâ”€â”€ presign.go
  â”‚   â”‚   â”œâ”€â”€ invalidation.go
  â”‚   â”‚   â””â”€â”€ providers/
  â”‚   â”‚       â”œâ”€â”€ cloudflare.go
  â”‚   â”‚       â”œâ”€â”€ cloudfront.go
  â”‚   â”‚       â””â”€â”€ generic.go
  â”‚   â”‚
  â”‚   â”œâ”€â”€ config/
  â”‚   â”‚   â”œâ”€â”€ config.go
  â”‚   â”‚   â”œâ”€â”€ validate.go
  â”‚   â”‚   â””â”€â”€ defaults.go
  â”‚   â”‚
  â”‚   â””â”€â”€ telemetry/
  â”‚       â”œâ”€â”€ metrics.go
  â”‚       â”œâ”€â”€ tracing.go
  â”‚       â””â”€â”€ logging.go
  â”‚
  â”œâ”€â”€ pkg/
  â”‚   â”œâ”€â”€ s3types/                     # S3 XML types (shared)
  â”‚   â”œâ”€â”€ checksum/
  â”‚   â””â”€â”€ byteutil/                    # aligned buffers, pools
  â”‚
  â”œâ”€â”€ test/
  â”‚   â”œâ”€â”€ integration/
  â”‚   â”œâ”€â”€ e2e/
  â”‚   â”œâ”€â”€ benchmark/
  â”‚   â””â”€â”€ chaos/                       # chaos engineering tests
  â”‚
  â”œâ”€â”€ deploy/
  â”‚   â”œâ”€â”€ docker/
  â”‚   â”‚   â”œâ”€â”€ Dockerfile
  â”‚   â”‚   â””â”€â”€ docker-compose.yml
  â”‚   â”œâ”€â”€ helm/
  â”‚   â”‚   â””â”€â”€ openendpoint/
  â”‚   â”œâ”€â”€ ansible/
  â”‚   â””â”€â”€ terraform/
  â”‚
  â”œâ”€â”€ docs/
  â”‚   â”œâ”€â”€ architecture.md
  â”‚   â”œâ”€â”€ api-reference.md
  â”‚   â”œâ”€â”€ deployment.md
  â”‚   â”œâ”€â”€ clustering.md
  â”‚   â”œâ”€â”€ federation.md
  â”‚   â””â”€â”€ performance-tuning.md
  â”‚
  â”œâ”€â”€ scripts/
  â”‚   â”œâ”€â”€ build.sh
  â”‚   â”œâ”€â”€ test.sh
  â”‚   â””â”€â”€ release.sh
  â”‚
  â”œâ”€â”€ go.mod
  â”œâ”€â”€ go.sum
  â”œâ”€â”€ Makefile
  â”œâ”€â”€ LICENSE                          # Apache 2.0
  â””â”€â”€ README.md


Repo 2: openendpoint/dashboard (Web UI)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Next.js dashboard application.

  dashboard/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ app/
  â”‚   â”‚   â”œâ”€â”€ layout.tsx
  â”‚   â”‚   â”œâ”€â”€ page.tsx                 # Dashboard home
  â”‚   â”‚   â”œâ”€â”€ buckets/
  â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx             # Bucket list
  â”‚   â”‚   â”‚   â””â”€â”€ [name]/
  â”‚   â”‚   â”‚       â”œâ”€â”€ page.tsx         # Object browser
  â”‚   â”‚   â”‚       â””â”€â”€ settings/
  â”‚   â”‚   â”œâ”€â”€ nodes/                   # v2
  â”‚   â”‚   â”œâ”€â”€ regions/                 # v3
  â”‚   â”‚   â”œâ”€â”€ backups/                 # v2
  â”‚   â”‚   â”œâ”€â”€ access/
  â”‚   â”‚   â”œâ”€â”€ analytics/              # v3
  â”‚   â”‚   â”œâ”€â”€ explorer/               # API explorer
  â”‚   â”‚   â””â”€â”€ settings/
  â”‚   â”‚
  â”‚   â”œâ”€â”€ components/
  â”‚   â”‚   â”œâ”€â”€ ui/                      # shadcn/ui
  â”‚   â”‚   â”œâ”€â”€ bucket/
  â”‚   â”‚   â”‚   â”œâ”€â”€ BucketList.tsx
  â”‚   â”‚   â”‚   â”œâ”€â”€ CreateBucketDialog.tsx
  â”‚   â”‚   â”‚   â””â”€â”€ BucketStats.tsx
  â”‚   â”‚   â”œâ”€â”€ object/
  â”‚   â”‚   â”‚   â”œâ”€â”€ ObjectBrowser.tsx
  â”‚   â”‚   â”‚   â”œâ”€â”€ ObjectPreview.tsx
  â”‚   â”‚   â”‚   â”œâ”€â”€ UploadDropzone.tsx
  â”‚   â”‚   â”‚   â”œâ”€â”€ VersionHistory.tsx
  â”‚   â”‚   â”‚   â””â”€â”€ ShareDialog.tsx
  â”‚   â”‚   â”œâ”€â”€ cluster/
  â”‚   â”‚   â”‚   â”œâ”€â”€ ClusterTopology.tsx  # D3 visualization
  â”‚   â”‚   â”‚   â”œâ”€â”€ NodeCard.tsx
  â”‚   â”‚   â”‚   â””â”€â”€ RebalanceProgress.tsx
  â”‚   â”‚   â”œâ”€â”€ region/
  â”‚   â”‚   â”‚   â”œâ”€â”€ WorldMap.tsx
  â”‚   â”‚   â”‚   â””â”€â”€ ReplicationStatus.tsx
  â”‚   â”‚   â”œâ”€â”€ charts/
  â”‚   â”‚   â”‚   â”œâ”€â”€ StorageGauge.tsx
  â”‚   â”‚   â”‚   â”œâ”€â”€ RequestRateChart.tsx
  â”‚   â”‚   â”‚   â””â”€â”€ BandwidthChart.tsx
  â”‚   â”‚   â””â”€â”€ layout/
  â”‚   â”‚       â”œâ”€â”€ Sidebar.tsx
  â”‚   â”‚       â”œâ”€â”€ Header.tsx
  â”‚   â”‚       â””â”€â”€ CommandPalette.tsx   # Cmd+K search
  â”‚   â”‚
  â”‚   â”œâ”€â”€ hooks/
  â”‚   â”‚   â”œâ”€â”€ useBuckets.ts
  â”‚   â”‚   â”œâ”€â”€ useObjects.ts
  â”‚   â”‚   â”œâ”€â”€ useCluster.ts
  â”‚   â”‚   â”œâ”€â”€ useMetrics.ts
  â”‚   â”‚   â””â”€â”€ useRealtimeEvents.ts
  â”‚   â”‚
  â”‚   â”œâ”€â”€ lib/
  â”‚   â”‚   â”œâ”€â”€ api-client.ts            # OpenEndpoint API client
  â”‚   â”‚   â”œâ”€â”€ s3-client.ts             # S3 operations
  â”‚   â”‚   â””â”€â”€ utils.ts
  â”‚   â”‚
  â”‚   â””â”€â”€ types/
  â”‚       â”œâ”€â”€ bucket.ts
  â”‚       â”œâ”€â”€ object.ts
  â”‚       â”œâ”€â”€ cluster.ts
  â”‚       â””â”€â”€ api.ts
  â”‚
  â”œâ”€â”€ public/
  â”œâ”€â”€ package.json
  â”œâ”€â”€ next.config.ts
  â”œâ”€â”€ tailwind.config.ts
  â”œâ”€â”€ tsconfig.json
  â””â”€â”€ Dockerfile


Repo 3: openendpoint/docs (Documentation)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Documentation website (Docusaurus or similar).

  docs/
  â”œâ”€â”€ docs/
  â”‚   â”œâ”€â”€ getting-started/
  â”‚   â”œâ”€â”€ configuration/
  â”‚   â”œâ”€â”€ s3-compatibility/
  â”‚   â”œâ”€â”€ clustering/
  â”‚   â”œâ”€â”€ federation/
  â”‚   â”œâ”€â”€ backup-restore/
  â”‚   â”œâ”€â”€ cdn-integration/
  â”‚   â”œâ”€â”€ security/
  â”‚   â”œâ”€â”€ performance/
  â”‚   â”œâ”€â”€ api-reference/
  â”‚   â””â”€â”€ troubleshooting/
  â””â”€â”€ docusaurus.config.js


Repo 4: openendpoint/helm-charts
Repo 5: openendpoint/terraform-provider
Repo 6: openendpoint/sdk-go (future)
Repo 7: openendpoint/sdk-js (future)
Repo 8: openendpoint/sdk-python (future)
```

---

## 21. Competitive Analysis

```
Feature Comparison Matrix:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                    OpenEndpoint  MinIO     SeaweedFS  Ceph RGW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
License             Apache 2.0    AGPLv3    Apache 2.0 LGPL
Language            Go            Go        Go         C++
Single Binary       âœ…            âœ…         âœ…         âŒ
S3 Compatible       âœ…            âœ…         âœ…         âœ…
Web Dashboard       âœ… (React)    Basic      âŒ         âŒ
Multi-Region        âœ… (v3)       Enterprise âœ…         âœ…
CDN Integration     âœ… (v3)       âŒ         âŒ         âŒ
Pluggable Backends  âœ…            âŒ         âœ…         âŒ
Packed Volumes      âœ…            âŒ         âœ…         âŒ
Erasure Coding      âœ… (v2)       âœ…         âœ…         âœ…
Object Versioning   âœ…            âœ…         âŒ         âœ…
Lifecycle Policies  âœ…            âœ…         âœ…         âœ…
Backup Targets      âœ… (v2)       Basic      âŒ         âŒ
Mirror Mode         âœ… (v2)       âœ…         âŒ         âœ…
IAM Policies        âœ… (v4)       âœ…         âŒ         âœ…
Object Lock/WORM    âœ… (v4)       âœ…         âŒ         âœ…
S3 Select           âœ… (v5)       âœ…         âŒ         âœ…
Event Notifications âœ… (v4)       âœ…         âŒ         âœ…
CLI Quality         âœ…            Good       Basic      Complex
Developer DX        âœ…âœ…          Good       Basic      Poor
Memory Footprint    Low           Medium     Low        High
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

---

## 22. Implementation Roadmap

### v1.0 â€” "Foundation" (12 weeks)

```
Week 1-2: Project Setup + Storage Layer
  â”œâ”€â”€ Go module, Makefile, CI pipeline
  â”œâ”€â”€ StorageBackend interface
  â”œâ”€â”€ Flat file backend implementation
  â”œâ”€â”€ Unit tests with table-driven tests
  â””â”€â”€ Benchmark framework

Week 3-4: Metadata Layer + Core Engine
  â”œâ”€â”€ MetadataStore interface
  â”œâ”€â”€ Pebble implementation
  â”œâ”€â”€ bbolt implementation
  â”œâ”€â”€ ObjectService (Put, Get, Delete, Head)
  â”œâ”€â”€ Sharded per-object locking
  â””â”€â”€ Integration tests

Week 5-6: S3 API
  â”œâ”€â”€ HTTP router (chi)
  â”œâ”€â”€ All CRUD handlers + ListObjectsV2
  â”œâ”€â”€ S3 XML serialization/deserialization
  â”œâ”€â”€ AWS Signature V4 verification
  â”œâ”€â”€ Presigned URL generation + verification
  â”œâ”€â”€ Virtual-hosted style support
  â””â”€â”€ AWS SDK compatibility tests

Week 7-8: Multipart Upload
  â”œâ”€â”€ InitiateMultipartUpload
  â”œâ”€â”€ UploadPart + part storage
  â”œâ”€â”€ CompleteMultipartUpload (concatenation)
  â”œâ”€â”€ AbortMultipartUpload + cleanup
  â”œâ”€â”€ ListParts, ListMultipartUploads
  â””â”€â”€ Large file upload tests (1GB+)

Week 9-10: Versioning + Lifecycle
  â”œâ”€â”€ Versioning state machine
  â”œâ”€â”€ Version-aware CRUD operations
  â”œâ”€â”€ Delete markers
  â”œâ”€â”€ ListObjectVersions
  â”œâ”€â”€ Lifecycle rule engine
  â”œâ”€â”€ Background expiration processor
  â””â”€â”€ Noncurrent version cleanup

Week 11: Packed Volume Backend
  â”œâ”€â”€ Volume file format (read/write)
  â”œâ”€â”€ Needle operations
  â”œâ”€â”€ In-memory index + WAL
  â”œâ”€â”€ Background compaction
  â””â”€â”€ Backend-agnostic integration tests

Week 12: CLI + Dashboard MVP + Polish
  â”œâ”€â”€ openep CLI (basic commands)
  â”œâ”€â”€ Dashboard MVP (bucket browse, upload)
  â”œâ”€â”€ Docker image + Helm chart skeleton
  â”œâ”€â”€ Prometheus metrics endpoint
  â”œâ”€â”€ Health + readiness endpoints
  â”œâ”€â”€ README, quickstart guide
  â””â”€â”€ Release v1.0.0

v2.0 â€” "Cluster" (16 weeks after v1)
v3.0 â€” "Federation" (16 weeks after v2)
v4.0 â€” "Platform" (20 weeks after v3)
v5.0 â€” "Intelligence" (20 weeks after v4)
```

---

*OpenEndpoint â€” Your endpoints. Your data. Your rules.*

*This document is the complete technical vision for OpenEndpoint.
It evolves with the project. Every decision here has been made
with the goal of building the best self-hosted object storage
platform in the world.*
